diff --git a/src/services/machineLearning/machineLearningService.ts b/src/services/machineLearning/machineLearningService.ts
index 17624a18d5f..e92a8f816b1 100644
--- a/src/services/machineLearning/machineLearningService.ts
+++ b/src/services/machineLearning/machineLearningService.ts
@@ -29,6 +29,7 @@ import { MAX_ML_SYNC_ERROR_COUNT } from 'constants/machineLearning/config';
 import FaceService from './faceService';
 import PeopleService from './peopleService';
 import ObjectService from './objectService';
+import TextService from './textService';
 class MachineLearningService {
     private initialized = false;
     // private faceDetectionService: FaceDetectionService;
@@ -408,6 +409,8 @@ class MachineLearningService {
 
         await ObjectService.syncFileObjectDetections(syncContext, fileContext);
 
+        await TextService.syncFileTextDetections(syncContext, fileContext);
+
         fileContext.tfImage && fileContext.tfImage.dispose();
         fileContext.imageBitmap && fileContext.imageBitmap.close();
         // console.log('8 TF Memory stats: ', tf.memory());
diff --git a/src/services/machineLearning/ssdMobileNetV2Service.ts b/src/services/machineLearning/ssdMobileNetV2Service.ts
index f50741ac334..b278284b001 100644
--- a/src/services/machineLearning/ssdMobileNetV2Service.ts
+++ b/src/services/machineLearning/ssdMobileNetV2Service.ts
@@ -31,12 +31,6 @@ class SSDMobileNetV2 implements ObjectDetectionService {
         );
     }
 
-    public async detectObjects(image: ImageBitmap): Promise<ObjectDetection[]> {
-        const results = await this.detectObjectUsingModel(image);
-
-        return results;
-    }
-
     private async getSSDMobileNetV2Model() {
         if (!this.ssdMobileNetV2Model) {
             await this.init();
@@ -45,23 +39,17 @@ class SSDMobileNetV2 implements ObjectDetectionService {
         return this.ssdMobileNetV2Model;
     }
 
-    private disposeSSDMobileNetV2Model() {
-        if (this.ssdMobileNetV2Model !== null) {
-            this.ssdMobileNetV2Model = null;
-        }
-    }
-
-    public async detectObjectUsingModel(imageBitmap: ImageBitmap) {
+    public async detectObjects(image: ImageBitmap): Promise<ObjectDetection[]> {
         const ssdMobileNetV2Model = await this.getSSDMobileNetV2Model();
-        const tfImage = tf.browser.fromPixels(imageBitmap);
-        const predictions = await ssdMobileNetV2Model.detect(tfImage);
-        return predictions;
+        const tfImage = tf.browser.fromPixels(image);
+        const detections = await ssdMobileNetV2Model.detect(tfImage);
+        return detections;
     }
 
     public async dispose() {
         const ssdMobileNetV2Model = await this.getSSDMobileNetV2Model();
         ssdMobileNetV2Model?.dispose();
-        this.disposeSSDMobileNetV2Model();
+        this.ssdMobileNetV2Model = null;
     }
 }
 
diff --git a/src/services/machineLearning/tesseractService.ts b/src/services/machineLearning/tesseractService.ts
new file mode 100644
index 00000000000..40517d497d6
--- /dev/null
+++ b/src/services/machineLearning/tesseractService.ts
@@ -0,0 +1,51 @@
+import {
+    TextDetectionMethod,
+    TextDetectionService,
+    Versioned,
+} from 'types/machineLearning';
+
+import Tesseract, { createWorker, RecognizeResult } from 'tesseract.js';
+
+class TesseractService implements TextDetectionService {
+    private tesseractWorker: Tesseract.Worker;
+    public method: Versioned<TextDetectionMethod>;
+
+    public constructor() {
+        this.method = {
+            value: 'Tesseract',
+            version: 1,
+        };
+    }
+
+    private async init() {
+        this.tesseractWorker = createWorker({
+            logger: (m) => console.log(m),
+        });
+        await this.tesseractWorker.load();
+        await this.tesseractWorker.loadLanguage('eng');
+        await this.tesseractWorker.initialize('eng');
+        console.log('loaded tesseract worker', this.tesseractWorker);
+    }
+
+    private async getTesseractWorker() {
+        if (!this.tesseractWorker) {
+            await this.init();
+        }
+
+        return this.tesseractWorker;
+    }
+
+    async detectText(image: Blob): Promise<RecognizeResult> {
+        const tesseractWorker = await this.getTesseractWorker();
+        const detections = await tesseractWorker.recognize(image);
+        return detections;
+    }
+
+    public async dispose() {
+        const tesseractWorker = await this.getTesseractWorker();
+        tesseractWorker?.terminate();
+        this.tesseractWorker = null;
+    }
+}
+
+export default new TesseractService();
diff --git a/src/services/machineLearning/textService.ts b/src/services/machineLearning/textService.ts
new file mode 100644
index 00000000000..52e0a10528b
--- /dev/null
+++ b/src/services/machineLearning/textService.ts
@@ -0,0 +1,124 @@
+import {
+    MLSyncContext,
+    MLSyncFileContext,
+    DetectedText,
+} from 'types/machineLearning';
+import { imageBitmapToBlob } from 'utils/image';
+import { isDifferentOrOld, getAllTextFromMap } from 'utils/machineLearning';
+import mlIDbStorage from 'utils/storage/mlIDbStorage';
+import ReaderService from './readerService';
+
+class TextService {
+    async syncFileTextDetections(
+        syncContext: MLSyncContext,
+        fileContext: MLSyncFileContext
+    ) {
+        const { oldMlFile, newMlFile } = fileContext;
+        if (
+            !isDifferentOrOld(
+                oldMlFile?.textDetectionMethod,
+                syncContext.textDetectionService.method
+            ) &&
+            oldMlFile?.imageSource === syncContext.config.imageSource
+        ) {
+            newMlFile.text = oldMlFile?.text;
+            newMlFile.imageSource = oldMlFile.imageSource;
+            newMlFile.imageDimensions = oldMlFile.imageDimensions;
+            newMlFile.textDetectionMethod = oldMlFile.textDetectionMethod;
+            return;
+        }
+
+        newMlFile.textDetectionMethod = syncContext.textDetectionService.method;
+        fileContext.newDetection = true;
+        const imageBitmap = await ReaderService.getImageBitmap(
+            syncContext,
+            fileContext
+        );
+        const textDetections =
+            await syncContext.textDetectionService.detectText(
+                await imageBitmapToBlob(imageBitmap)
+            );
+        // console.log('3 TF Memory stats: ', tf.memory());
+        // TODO: reenable faces filtering based on width
+        const detectedText: DetectedText = {
+            fileID: fileContext.enteFile.id,
+            detection: textDetections,
+        };
+        newMlFile.text = detectedText;
+        // ?.filter((f) =>
+        //     f.box.width > syncContext.config.faceDetection.minFaceSize
+        // );
+        console.log('[MLService] Detected text: ', newMlFile.text);
+    }
+
+    async getAllSyncedTextMap(syncContext: MLSyncContext) {
+        if (syncContext.allSyncedTextMap) {
+            return syncContext.allSyncedTextMap;
+        }
+
+        syncContext.allSyncedTextMap = await mlIDbStorage.getAllTextMap();
+        return syncContext.allSyncedTextMap;
+    }
+
+    public async getAllText() {
+        const allTextMap = await mlIDbStorage.getAllTextMap();
+        const allText = getAllTextFromMap(allTextMap);
+        return allText;
+    }
+
+    // public async clusterThingClasses(
+    //     syncContext: MLSyncContext
+    // ): Promise<ThingClass[]> {
+    //     const allTextMap = await this.getAllSyncedTextMap(syncContext);
+    //     const allText = getAllTextFromMap(allTextMap);
+    //     const textCluster = new Map<string, number[]>();
+    //     allObjects.map((object) => {
+    //         if (!objectClusters.has(object.detection.class)) {
+    //             objectClusters.set(object.detection.class, []);
+    //         }
+    //         const objectsInCluster = objectClusters.get(object.detection.class);
+    //         objectsInCluster.push(object.fileID);
+    //     });
+    //     return [...objectClusters.entries()].map(([className, files], id) => ({
+    //         id,
+    //         className,
+    //         files,
+    //     }));
+    // }
+
+    // async syncThingClassesIndex(syncContext: MLSyncContext) {
+    //     const filesVersion = await mlIDbStorage.getIndexVersion('files');
+    //     console.log(
+    //         'thingClasses',
+    //         await mlIDbStorage.getIndexVersion('thingClasses')
+    //     );
+    //     if (
+    //         filesVersion <= (await mlIDbStorage.getIndexVersion('thingClasses'))
+    //     ) {
+    //         console.log(
+    //             '[MLService] Skipping people index as already synced to latest version'
+    //         );
+    //         return;
+    //     }
+
+    //     const thingClasses = await this.clusterThingClasses(syncContext);
+
+    //     if (!thingClasses || thingClasses.length < 1) {
+    //         return;
+    //     }
+
+    //     await mlIDbStorage.clearAllThingClasses();
+
+    //     for (const thingClass of thingClasses) {
+    //         await mlIDbStorage.putThingClass(thingClass);
+    //     }
+
+    //     await mlIDbStorage.setIndexVersion('thingClasses', filesVersion);
+    // }
+
+    // async getAllThingClasses() {
+    //     return await mlIDbStorage.getAllThingClasses();
+    // }
+}
+
+export default new TextService();
diff --git a/src/services/searchService.ts b/src/services/searchService.ts
index d08c26076c7..bc8a7e9db50 100644
--- a/src/services/searchService.ts
+++ b/src/services/searchService.ts
@@ -17,6 +17,7 @@ import {
     SuggestionType,
 } from 'types/search';
 import ObjectService from './machineLearning/objectService';
+import textService from './machineLearning/textService';
 
 const ENDPOINT = getEndpoint();
 
@@ -181,3 +182,14 @@ export async function searchThing(searchPhrase: string) {
         )
         .map(({ className, files }) => ({ className, files }));
 }
+
+export async function searchText(searchPhrase: string) {
+    const texts = await textService.getAllText();
+    console.log(texts, searchPhrase);
+    return [];
+    // return texts
+    //     .filter((thingClass) =>
+    //         thingClass.className.toLocaleLowerCase().includes(searchPhrase)
+    //     )
+    //     .map(({ className, files }) => ({ className, files }));
+}
diff --git a/src/types/machineLearning/index.ts b/src/types/machineLearning/index.ts
index f5505f9aea3..f226abb64a1 100644
--- a/src/types/machineLearning/index.ts
+++ b/src/types/machineLearning/index.ts
@@ -14,7 +14,7 @@ import { EnteFile } from 'types/file';
 import { Config } from 'types/common/config';
 import { Dimensions } from 'types/image';
 import { Box, Point } from '../../../thirdparty/face-api/classes';
-import * as SSDMobileNet from '@tensorflow-models/coco-ssd';
+import Tesseract from 'tesseract.js';
 
 export interface MLSyncResult {
     nOutOfSyncFiles: number;
@@ -95,6 +95,8 @@ export declare type FaceDetectionMethod = 'BlazeFace' | 'FaceApiSSD';
 
 export declare type ObjectDetectionMethod = 'SSDMobileNetV2';
 
+export declare type TextDetectionMethod = 'Tesseract';
+
 export declare type FaceCropMethod = 'ArcFace';
 
 export declare type FaceAlignmentMethod =
@@ -203,10 +205,18 @@ export interface ThingClass {
     files: Array<number>;
 }
 
+export declare type TextDetection = Tesseract.RecognizeResult;
+
+export interface DetectedText {
+    fileID: number;
+    detection: TextDetection;
+}
+
 export interface MlFileData {
     fileId: number;
     faces?: Face[];
     things?: Thing[];
+    text?: DetectedText;
     imageSource?: ImageType;
     imageDimensions?: Dimensions;
     faceDetectionMethod?: Versioned<FaceDetectionMethod>;
@@ -214,6 +224,7 @@ export interface MlFileData {
     faceAlignmentMethod?: Versioned<FaceAlignmentMethod>;
     faceEmbeddingMethod?: Versioned<FaceEmbeddingMethod>;
     objectDetectionMethod?: Versioned<ObjectDetectionMethod>;
+    textDetectionMethod?: Versioned<TextDetectionMethod>;
     mlVersion: number;
     errorCount: number;
     lastErrorMessage?: string;
@@ -291,6 +302,7 @@ export interface MLSyncContext {
     faceEmbeddingService: FaceEmbeddingService;
     faceClusteringService: ClusteringService;
     objectDetectionService?: ObjectDetectionService;
+    textDetectionService?: TextDetectionService;
 
     localFilesMap: Map<number, EnteFile>;
     outOfSyncFiles: EnteFile[];
@@ -298,6 +310,7 @@ export interface MLSyncContext {
     nSyncedFaces: number;
     allSyncedFacesMap?: Map<number, Array<Face>>;
     allSyncedThingsMap?: Map<number, Array<Thing>>;
+    allSyncedTextMap?: Map<number, DetectedText>;
     tsne?: any;
 
     error?: Error;
@@ -351,7 +364,14 @@ export interface FaceDetectionService {
 export interface ObjectDetectionService {
     method: Versioned<ObjectDetectionMethod>;
     // init(): Promise<void>;
-    detectObjects(image: ImageBitmap): Promise<SSDMobileNet.DetectedObject[]>;
+    detectObjects(image: ImageBitmap): Promise<ObjectDetection[]>;
+    dispose(): Promise<void>;
+}
+
+export interface TextDetectionService {
+    method: Versioned<TextDetectionMethod>;
+    // init(): Promise<void>;
+    detectText(image: Blob): Promise<TextDetection>;
     dispose(): Promise<void>;
 }
 
diff --git a/src/utils/machineLearning/index.ts b/src/utils/machineLearning/index.ts
index f376b60173b..8dc22196633 100644
--- a/src/utils/machineLearning/index.ts
+++ b/src/utils/machineLearning/index.ts
@@ -18,6 +18,7 @@ import {
     MlFileData,
     Person,
     Versioned,
+    DetectedText,
 } from 'types/machineLearning';
 // import { mlFilesStore, mlPeopleStore } from 'utils/storage/mlStorage';
 import { convertForPreview, needsConversionForPreview } from 'utils/file';
@@ -204,6 +205,9 @@ export function getAllThingsFromMap(allObjectsMap: Map<number, Array<Thing>>) {
     return [...allObjectsMap.values()].flat();
 }
 
+export function getAllTextFromMap(allTextMap: Map<number, DetectedText>) {
+    return [...allTextMap.values()];
+}
 export async function getLocalFile(fileId: number) {
     const localFiles = await getLocalFiles();
     return localFiles.find((f) => f.id === fileId);
diff --git a/src/utils/storage/mlIDbStorage.ts b/src/utils/storage/mlIDbStorage.ts
index f01b9c4f2fa..0e283ea5d1f 100644
--- a/src/utils/storage/mlIDbStorage.ts
+++ b/src/utils/storage/mlIDbStorage.ts
@@ -14,6 +14,7 @@ import {
 } from 'idb';
 import { Config } from 'types/common/config';
 import {
+    DetectedText,
     Face,
     MlFileData,
     MLLibraryData,
@@ -310,6 +311,21 @@ class MLIDbStorage {
         return allThingsMap;
     }
 
+    public async getAllTextMap() {
+        console.time('getAllTextMap');
+        const db = await this.db;
+        const allFiles = await db.getAll('files');
+        const allTextMap = new Map<number, DetectedText>();
+        allFiles.forEach(
+            (mlFileData) =>
+                mlFileData.text &&
+                allTextMap.set(mlFileData.fileId, mlFileData.text)
+        );
+        console.timeEnd('getAllTextMap');
+
+        return allTextMap;
+    }
+
     public async getPerson(id: number) {
         const db = await this.db;
         return db.get('people', id);
