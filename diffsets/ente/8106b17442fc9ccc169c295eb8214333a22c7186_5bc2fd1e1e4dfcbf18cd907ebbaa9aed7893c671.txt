diff --git a/mobile/lib/services/machine_learning/semantic_search/clip/clip_text_encoder.dart b/mobile/lib/services/machine_learning/semantic_search/clip/clip_text_encoder.dart
index 58a042c5343..6f74ab48c7b 100644
--- a/mobile/lib/services/machine_learning/semantic_search/clip/clip_text_encoder.dart
+++ b/mobile/lib/services/machine_learning/semantic_search/clip/clip_text_encoder.dart
@@ -33,7 +33,8 @@ class ClipTextEncoder extends MlModel {
   static Future<List<double>> infer(Map args) async {
     final text = args["text"];
     final address = args["address"] as int;
-    final List<int> tokenize = await ClipTextTokenizer.instance.tokenize(text);
+    final vocabPath = args["vocabPath"] as String;
+    final List<int> tokenize = await ClipTextTokenizer.instance.tokenize(text, vocabPath);
     final int32list = Int32List.fromList(tokenize);
     return _runFFIBasedPredict(int32list, address);
   }
diff --git a/mobile/lib/services/machine_learning/semantic_search/clip/clip_text_tokenizer.dart b/mobile/lib/services/machine_learning/semantic_search/clip/clip_text_tokenizer.dart
index 404234effc7..a0c3d1c6c02 100644
--- a/mobile/lib/services/machine_learning/semantic_search/clip/clip_text_tokenizer.dart
+++ b/mobile/lib/services/machine_learning/semantic_search/clip/clip_text_tokenizer.dart
@@ -1,8 +1,8 @@
 import "dart:convert";
+import "dart:io" show File;
 import "dart:math";
 
 import "package:html_unescape/html_unescape.dart";
-import "package:photos/services/remote_assets_service.dart";
 import "package:tuple/tuple.dart";
 
 class ClipTextTokenizer {
@@ -38,18 +38,17 @@ class ClipTextTokenizer {
   static final instance = ClipTextTokenizer._privateConstructor();
   factory ClipTextTokenizer() => instance;
 
-  Future<List<int>> tokenize(String text) async {
-    await _init();
+  Future<List<int>> tokenize(String text, String vocabPath) async {
+    await _init(vocabPath);
     var tokens = _encode(text);
     tokens =
         [sot] + tokens.sublist(0, min(totalTokens - 2, tokens.length)) + [eot];
     return tokens + List.filled(totalTokens - tokens.length, 0);
   }
 
-  Future<void> _init() async {
+  Future<void> _init(String vocabPath) async {
     if (_isInitialized) return;
-    final vocabFile =
-        await RemoteAssetsService.instance.getAsset(kVocabRemotePath);
+    final vocabFile = File(vocabPath);
     final String vocabulary = await vocabFile.readAsString();
     this.vocabulary = vocabulary;
     byteEncoder = _bytesToUnicode();
diff --git a/mobile/lib/services/machine_learning/semantic_search/semantic_search_service.dart b/mobile/lib/services/machine_learning/semantic_search/semantic_search_service.dart
index 5d6475bb55b..ca45633ac13 100644
--- a/mobile/lib/services/machine_learning/semantic_search/semantic_search_service.dart
+++ b/mobile/lib/services/machine_learning/semantic_search/semantic_search_service.dart
@@ -19,7 +19,9 @@ import "package:photos/services/machine_learning/face_ml/face_clustering/cosine_
 import "package:photos/services/machine_learning/ml_result.dart";
 import "package:photos/services/machine_learning/semantic_search/clip/clip_image_encoder.dart";
 import "package:photos/services/machine_learning/semantic_search/clip/clip_text_encoder.dart";
+import "package:photos/services/machine_learning/semantic_search/clip/clip_text_tokenizer.dart";
 import 'package:photos/services/machine_learning/semantic_search/embedding_store.dart';
+import "package:photos/services/remote_assets_service.dart";
 import "package:photos/utils/debouncer.dart";
 import "package:photos/utils/local_settings.dart";
 import "package:photos/utils/ml_util.dart";
@@ -296,16 +298,17 @@ class SemanticSearchService {
     }
     try {
       final int clipAddress = ClipTextEncoder.instance.sessionAddress;
-      // final textEmbedding = await _computer.compute(
-      //   ClipTextEncoder.infer,
-      //   param: {
-      //     "text": query,
-      //     "address": clipAddress,
-      //   },
-      // ) as List<double>;
-      final textEmbedding = await ClipTextEncoder.infer(
-        {"text": query, "address": clipAddress},
-      );
+      const remotePath = ClipTextTokenizer.kVocabRemotePath;
+      final String tokenizerVocabPath =
+          await RemoteAssetsService.instance.getAssetPath(remotePath);
+      final textEmbedding = await _computer.compute(
+        ClipTextEncoder.infer,
+        param: {
+          "text": query,
+          "address": clipAddress,
+          "vocabPath": tokenizerVocabPath,
+        },
+      ) as List<double>;
       _queryCache.put(query, textEmbedding);
       return textEmbedding;
     } catch (e) {
diff --git a/mobile/lib/services/remote_assets_service.dart b/mobile/lib/services/remote_assets_service.dart
index b9bed09b506..bbceb4ac135 100644
--- a/mobile/lib/services/remote_assets_service.dart
+++ b/mobile/lib/services/remote_assets_service.dart
@@ -32,6 +32,20 @@ class RemoteAssetsService {
     }
   }
 
+  Future<String> getAssetPath(String remotePath, {bool refetch = false}) async {
+    final path = await _getLocalPath(remotePath);
+    final file = File(path);
+    if (file.existsSync() && !refetch) {
+      _logger.info("Returning path of cached file for $remotePath");
+      return file.path;
+    } else {
+      final tempFile = File(path + ".temp");
+      await _downloadFile(remotePath, tempFile.path);
+      tempFile.renameSync(path);
+      return path;
+    }
+  }
+
   ///Returns asset if the remote asset is new compared to the local copy of it
   Future<File?> getAssetIfUpdated(String remotePath) async {
     try {
