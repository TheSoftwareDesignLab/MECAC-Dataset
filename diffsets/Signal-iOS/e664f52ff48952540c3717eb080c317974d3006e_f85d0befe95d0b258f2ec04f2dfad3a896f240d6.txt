diff --git a/Signal/src/ViewControllers/ConversationView/Cells/OWSQuotedMessageView.m b/Signal/src/ViewControllers/ConversationView/Cells/OWSQuotedMessageView.m
index 405d5769a3a..2b6bb6c2809 100644
--- a/Signal/src/ViewControllers/ConversationView/Cells/OWSQuotedMessageView.m
+++ b/Signal/src/ViewControllers/ConversationView/Cells/OWSQuotedMessageView.m
@@ -498,20 +498,22 @@ - (nullable NSString *)fileTypeForSnippet
     if ([MIMETypeUtil isAudio:contentType]) {
         return NSLocalizedString(
             @"QUOTED_REPLY_TYPE_AUDIO", @"Indicates this message is a quoted reply to an audio file.");
-    } else if ([MIMETypeUtil isVideo:contentType]) {
-        return NSLocalizedString(
-            @"QUOTED_REPLY_TYPE_VIDEO", @"Indicates this message is a quoted reply to a video file.");
-    } else if ([MIMETypeUtil isImage:contentType]) {
-        return NSLocalizedString(
-            @"QUOTED_REPLY_TYPE_IMAGE", @"Indicates this message is a quoted reply to an image file.");
     } else if ([MIMETypeUtil isAnimated:contentType]) {
         if ([contentType caseInsensitiveCompare:OWSMimeTypeImageGif] == NSOrderedSame) {
             return NSLocalizedString(
-                @"QUOTED_REPLY_TYPE_GIF", @"Indicates this message is a quoted reply to animated GIF file.");
+                                     @"QUOTED_REPLY_TYPE_GIF", @"Indicates this message is a quoted reply to animated GIF file.");
         } else {
             return NSLocalizedString(
-                @"QUOTED_REPLY_TYPE_IMAGE", @"Indicates this message is a quoted reply to an image file.");
+                                     @"QUOTED_REPLY_TYPE_IMAGE", @"Indicates this message is a quoted reply to an image file.");
         }
+    } else if (self.quotedMessage.attachmentStream.isLoopingVideo) {
+        return NSLocalizedString(@"QUOTED_REPLY_TYPE_GIF", @"Indicates this message is a quoted reply to animated GIF file.");
+    } else if ([MIMETypeUtil isVideo:contentType]) {
+        return NSLocalizedString(
+            @"QUOTED_REPLY_TYPE_VIDEO", @"Indicates this message is a quoted reply to a video file.");
+    } else if ([MIMETypeUtil isImage:contentType]) {
+        return NSLocalizedString(
+            @"QUOTED_REPLY_TYPE_IMAGE", @"Indicates this message is a quoted reply to an image file.");
     }
     return nil;
 }
diff --git a/Signal/src/ViewControllers/MediaGallery/MediaDetailViewController.m b/Signal/src/ViewControllers/MediaGallery/MediaDetailViewController.m
index 6515b78de74..1dd90b86aa2 100644
--- a/Signal/src/ViewControllers/MediaGallery/MediaDetailViewController.m
+++ b/Signal/src/ViewControllers/MediaGallery/MediaDetailViewController.m
@@ -293,6 +293,11 @@ - (UIView *)buildLoopingVideoPlayerView
 
     LoopingVideoView *view = [[LoopingVideoView alloc] init];
     view.video = video;
+
+    [NSLayoutConstraint autoSetPriority:UILayoutPriorityDefaultLow
+                         forConstraints:^{
+        [view autoSetDimensionsToSize:self.image.size];
+    }];
     return view;
 }
 
@@ -397,13 +402,13 @@ - (void)centerMediaViewConstraints
     OWSAssertDebug(self.scrollView);
 
     CGSize scrollViewSize = self.scrollView.bounds.size;
-    CGSize imageViewSize = self.mediaView.frame.size;
+    CGSize mediaSize = self.mediaView.frame.size;
 
-    CGFloat yOffset = MAX(0, (scrollViewSize.height - imageViewSize.height) / 2);
+    CGFloat yOffset = MAX(0, (scrollViewSize.height - mediaSize.height) / 2);
     self.mediaViewTopConstraint.constant = yOffset;
     self.mediaViewBottomConstraint.constant = yOffset;
 
-    CGFloat xOffset = MAX(0, (scrollViewSize.width - imageViewSize.width) / 2);
+    CGFloat xOffset = MAX(0, (scrollViewSize.width - mediaSize.width) / 2);
     self.mediaViewLeadingConstraint.constant = xOffset;
     self.mediaViewTrailingConstraint.constant = -xOffset;
 }
diff --git a/SignalMessaging/ViewControllers/MediaMessageView.swift b/SignalMessaging/ViewControllers/MediaMessageView.swift
index d4027d7c2e2..85f53110122 100644
--- a/SignalMessaging/ViewControllers/MediaMessageView.swift
+++ b/SignalMessaging/ViewControllers/MediaMessageView.swift
@@ -173,7 +173,6 @@ public class MediaMessageView: UIView, OWSAudioPlayerDelegate {
         }
         let loopingVideoView = LoopingVideoView()
         loopingVideoView.video = video
-        loopingVideoView.placeholderProvider = { previewImage }
 
         addSubviewWithScaleAspectFitLayout(view: loopingVideoView, aspectRatio: previewImage.size.aspectRatio)
         contentView = loopingVideoView
diff --git a/SignalMessaging/ViewControllers/OWSViewController.m b/SignalMessaging/ViewControllers/OWSViewController.m
index d41eeb51582..8de2b88b45f 100644
--- a/SignalMessaging/ViewControllers/OWSViewController.m
+++ b/SignalMessaging/ViewControllers/OWSViewController.m
@@ -223,6 +223,15 @@ - (void)handleKeyboardNotificationBase:(NSNotification *)notification
     }
 
     CGRect keyboardEndFrame = [keyboardEndFrameValue CGRectValue];
+    if (CGRectEqualToRect(keyboardEndFrame, CGRectZero)) {
+        // If reduce motion+crossfade transitions is on, in iOS 14 UIKit vends out a keyboard end frame
+        // of CGRect zero. This breaks the math below.
+        //
+        // If our keyboard end frame is CGRectZero, build a fake rect that's translated off the bottom edge.
+        CGRect deviceBounds = UIScreen.mainScreen.bounds;
+        keyboardEndFrame = CGRectOffset(deviceBounds, 0, deviceBounds.size.height);
+    }
+
     CGRect keyboardEndFrameConverted = [self.view convertRect:keyboardEndFrame fromView:nil];
     // Adjust the position of the bottom view to account for the keyboard's
     // intrusion into the view.
@@ -250,7 +259,7 @@ - (void)handleKeyboardNotificationBase:(NSNotification *)notification
     };
 
 
-    if (self.shouldAnimateBottomLayout && duration > 0) {
+    if (self.shouldAnimateBottomLayout && duration > 0 && !UIAccessibilityIsReduceMotionEnabled()) {
         [UIView beginAnimations:@"keyboardStateChange" context:NULL];
         [UIView setAnimationBeginsFromCurrentState:YES];
         [UIView setAnimationCurve:curve];
diff --git a/SignalMessaging/Views/LoopingVideoView.swift b/SignalMessaging/Views/LoopingVideoView.swift
index 46d47b78786..a194c304f28 100644
--- a/SignalMessaging/Views/LoopingVideoView.swift
+++ b/SignalMessaging/Views/LoopingVideoView.swift
@@ -10,30 +10,29 @@ import PromiseKit
 /// Any LoopingVideoViews playing this instance will all be kept in sync
 @objc
 public class LoopingVideo: NSObject {
-    fileprivate let playerItemPromise: Guarantee<AVPlayerItem?>
-    fileprivate var playerItem: AVPlayerItem? { playerItemPromise.value.flatMap { $0 } }
-    fileprivate var asset: AVAsset? { playerItem?.asset }
+    fileprivate let assetPromise: Guarantee<AVAsset?>
+    fileprivate var asset: AVAsset? { assetPromise.value.flatMap { $0 } }
 
     @objc
     public init?(url: URL) {
         guard OWSMediaUtils.isVideoOfValidContentTypeAndSize(path: url.path) else {
             return nil
         }
-        playerItemPromise = firstly(on: .global(qos: .userInitiated)) {
-            let asset = AVAsset(url: url)
-            let item = AVPlayerItem(asset: asset, automaticallyLoadedAssetKeys: ["tracks"])
-            return OWSMediaUtils.isValidVideo(asset: asset) ? item : nil
-        }
+        assetPromise = firstly(on: .global(qos: .userInitiated)) { AVAsset(url: url) }
         super.init()
     }
 
+    func createPlayerItem() -> AVPlayerItem? {
+        guard let asset = asset else { return nil }
+        let item = AVPlayerItem(asset: asset, automaticallyLoadedAssetKeys: ["tracks"])
+        return OWSMediaUtils.isValidVideo(asset: asset) ? item : nil
+    }
+
     deinit {
-        playerItem?.cancelPendingSeeks()
         asset?.cancelLoading()
     }
 }
 
-// TODO: Multicast for syncing up two views?
 private class LoopingVideoPlayer: AVPlayer {
 
     override init() {
@@ -123,19 +122,21 @@ public class LoopingVideoView: UIView {
         didSet {
             guard video !== oldValue else { return }
             player.replaceCurrentItem(with: nil)
+            invalidateIntrinsicContentSize()
 
-            if let itemPromise = video?.playerItemPromise {
-                itemPromise.done(on: .global(qos: .userInitiated)) { item in
-                    guard item === self.video?.playerItem else { return }
+            if let assetPromise = video?.assetPromise {
+                assetPromise.done(on: .global(qos: .userInitiated)) { asset in
+                    guard asset === self.video?.asset else { return }
 
-                    if let item = item {
-                        self.player.replaceCurrentItem(with: item)
+                    if let asset = asset {
+                        let playerItem = AVPlayerItem(asset: asset, automaticallyLoadedAssetKeys: ["tracks"])
+                        self.player.replaceCurrentItem(with: playerItem)
                         self.player.play()
+
+                        DispatchQueue.main.async { self.invalidateIntrinsicContentSize() }
                     }
                 }
             }
-            displayReadyObserver = nil
-            invalidateIntrinsicContentSize()
         }
     }
 
@@ -171,8 +172,8 @@ public class LoopingVideoView: UIView {
         guard let asset = video?.asset else {
             // If we have an outstanding promise, invalidate the size once it's complete
             // If there isn't, -noIntrinsicMetric is valid
-            if video?.playerItemPromise.isPending == true {
-                video?.playerItemPromise.done { _ in self.invalidateIntrinsicContentSize() }
+            if video?.assetPromise.isPending == true {
+                video?.assetPromise.done { _ in self.invalidateIntrinsicContentSize() }
             }
             return CGSize(square: UIView.noIntrinsicMetric)
         }
@@ -185,52 +186,4 @@ public class LoopingVideoView: UIView {
                        height: max($0.height, $1.height))
             }
     }
-
-    // MARK: - Placeholder Images
-
-    /// AVKit may not have the video ready in time for display. If a closure is provided here, LoopingAnimationView will invoke the closure to
-    /// fetch a placeholder image to present in the meantime while the video is prepared.
-    /// This image will be removed once the video is ready to play.
-    public var placeholderProvider: (() -> UIImage?)?
-
-    private var placeholderView: UIImageView?
-    private var displayReadyObserver: NSKeyValueObservation?
-
-    override public func draw(_ rect: CGRect) {
-        defer { super.draw(rect) }
-        guard video != nil else { return }
-        let isDisplayingPlaceholder = (placeholderView != nil)
-
-        // If we aren't ready for display, add an imageView to present the placeholder. Start listening
-        // for any changes so we can clean this up when the video layer is ready.
-        if !playerLayer.isReadyForDisplay,
-           !isDisplayingPlaceholder,
-           let placeholderProvider = placeholderProvider {
-
-            // First, set up our observer so we are notified once we can drop the placeholder
-            displayReadyObserver = playerLayer.observe(
-                \.isReadyForDisplay,
-                options: .new
-            ) { [weak self] (_, change) in
-                if change.newValue == true {
-                    self?.setNeedsDisplay()
-                }
-            }
-
-            // Then, add the placeholder image
-            let imageView = UIImageView()
-            imageView.contentMode = contentMode
-            imageView.image = placeholderProvider()
-
-            addSubview(imageView)
-            imageView.autoPinEdgesToSuperviewEdges()
-            placeholderView = imageView
-
-        } else if playerLayer.isReadyForDisplay {
-            // Cleanup. The video is ready to go.
-            displayReadyObserver = nil
-            placeholderView?.removeFromSuperview()
-            placeholderView = nil
-        }
-    }
 }
diff --git a/SignalServiceKit/src/Messages/Attachments/TSAttachment.m b/SignalServiceKit/src/Messages/Attachments/TSAttachment.m
index 54b75f5ac20..395c7d8a6ef 100644
--- a/SignalServiceKit/src/Messages/Attachments/TSAttachment.m
+++ b/SignalServiceKit/src/Messages/Attachments/TSAttachment.m
@@ -292,7 +292,7 @@ + (NSString *)collection {
 - (NSString *)description {
     NSString *attachmentString;
 
-    if (self.isAnimated) {
+    if (self.isAnimated || self.isLoopingVideo) {
         BOOL isGIF = ([self.contentType caseInsensitiveCompare:OWSMimeTypeImageGif] == NSOrderedSame);
         BOOL isLoopingVideo = self.isLoopingVideo && ([MIMETypeUtil isVideo:self.contentType]);
 
diff --git a/SignalServiceKit/src/Messages/Attachments/TSAttachmentStream.m b/SignalServiceKit/src/Messages/Attachments/TSAttachmentStream.m
index 15ab80ca518..08cbc6cd894 100644
--- a/SignalServiceKit/src/Messages/Attachments/TSAttachmentStream.m
+++ b/SignalServiceKit/src/Messages/Attachments/TSAttachmentStream.m
@@ -469,6 +469,10 @@ - (BOOL)isValidVisualMedia
         return YES;
     }
 
+    if (self.isLoopingVideo && self.isValidVideo) {
+        return YES;
+    }
+
     return NO;
 }
 
@@ -888,9 +892,11 @@ - (void)loadedThumbnailWithThumbnailDimensionPoints:(NSUInteger)thumbnailDimensi
             }
 
             if (originalSizePoints.width <= thumbnailDimensionPoints
-                && originalSizePoints.height <= thumbnailDimensionPoints) {
+                && originalSizePoints.height <= thumbnailDimensionPoints
+                && self.isImage) {
                 // There's no point in generating a thumbnail if the original is smaller than the
-                // thumbnail size.
+                // thumbnail size. Only do this for images. We still need to generate thumbnails
+                // for videos.
                 NSString *originalFilePath = self.originalFilePath;
                 UIImage *_Nullable originalImage = self.originalImage;
                 if (originalImage == nil) {
