diff --git a/Signal.xcodeproj/project.pbxproj b/Signal.xcodeproj/project.pbxproj
index 9ae972319d2..e9ebdd98c22 100644
--- a/Signal.xcodeproj/project.pbxproj
+++ b/Signal.xcodeproj/project.pbxproj
@@ -697,7 +697,7 @@
 		4C1885D2218F8E1C00B67051 /* PhotoGridViewCell.swift in Sources */ = {isa = PBXBuildFile; fileRef = 4C1885D1218F8E1C00B67051 /* PhotoGridViewCell.swift */; };
 		4C19A0FC227B356F007A0C7F /* DebugUIMessages+OWS.swift in Sources */ = {isa = PBXBuildFile; fileRef = 4C19A0FB227B356F007A0C7F /* DebugUIMessages+OWS.swift */; };
 		4C20B2B920CA10DE001BAC90 /* ConversationSearchViewController.swift in Sources */ = {isa = PBXBuildFile; fileRef = 4C20B2B820CA10DE001BAC90 /* ConversationSearchViewController.swift */; };
-		4C21D5D8223AC60F00EF8A77 /* PhotoCapture.swift in Sources */ = {isa = PBXBuildFile; fileRef = 4C21D5D7223AC60F00EF8A77 /* PhotoCapture.swift */; };
+		4C21D5D8223AC60F00EF8A77 /* CameraCaptureSession.swift in Sources */ = {isa = PBXBuildFile; fileRef = 4C21D5D7223AC60F00EF8A77 /* CameraCaptureSession.swift */; };
 		4C25768A23AD510800E0398D /* LoadMoreMessagesView.swift in Sources */ = {isa = PBXBuildFile; fileRef = 4C25768923AD510800E0398D /* LoadMoreMessagesView.swift */; };
 		4C2A538C23C5462300D28CD8 /* CVMessageMappingTest.swift in Sources */ = {isa = PBXBuildFile; fileRef = 4C2A538B23C5462300D28CD8 /* CVMessageMappingTest.swift */; };
 		4C2EBB7F2356B2B900BBC171 /* Deprecated_SecondaryLinkingSetDeviceNameViewController.swift in Sources */ = {isa = PBXBuildFile; fileRef = 4C2EBB7E2356B2B900BBC171 /* Deprecated_SecondaryLinkingSetDeviceNameViewController.swift */; };
@@ -3073,7 +3073,7 @@
 		4C1D233A218B6CDB00A0598F /* th */ = {isa = PBXFileReference; lastKnownFileType = text.plist.strings; name = th; path = translations/th.lproj/Localizable.strings; sourceTree = "<group>"; };
 		4C1D233B218B6D3100A0598F /* tr */ = {isa = PBXFileReference; lastKnownFileType = text.plist.strings; name = tr; path = translations/tr.lproj/Localizable.strings; sourceTree = "<group>"; };
 		4C20B2B820CA10DE001BAC90 /* ConversationSearchViewController.swift */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.swift; path = ConversationSearchViewController.swift; sourceTree = "<group>"; };
-		4C21D5D7223AC60F00EF8A77 /* PhotoCapture.swift */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.swift; path = PhotoCapture.swift; sourceTree = "<group>"; };
+		4C21D5D7223AC60F00EF8A77 /* CameraCaptureSession.swift */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.swift; path = CameraCaptureSession.swift; sourceTree = "<group>"; };
 		4C25768923AD510800E0398D /* LoadMoreMessagesView.swift */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.swift; path = LoadMoreMessagesView.swift; sourceTree = "<group>"; };
 		4C2A538B23C5462300D28CD8 /* CVMessageMappingTest.swift */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.swift; path = CVMessageMappingTest.swift; sourceTree = "<group>"; };
 		4C2EBB7E2356B2B900BBC171 /* Deprecated_SecondaryLinkingSetDeviceNameViewController.swift */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.swift; path = Deprecated_SecondaryLinkingSetDeviceNameViewController.swift; sourceTree = "<group>"; };
@@ -5297,9 +5297,9 @@
 			isa = PBXGroup;
 			children = (
 				32C584A725B81C6600256804 /* AvatarViewController.swift */,
+				4C21D5D7223AC60F00EF8A77 /* CameraCaptureSession.swift */,
 				34969559219B605E00DCFE74 /* ImagePickerController.swift */,
 				76FCCDBB27AB8FBE00BAA7F0 /* MediaControls.swift */,
-				4C21D5D7223AC60F00EF8A77 /* PhotoCapture.swift */,
 				E44AD4E524E98F430035D7B8 /* PhotoCaptureDismiss.swift */,
 				4CA485BA2232339F004B9E7D /* PhotoCaptureViewController.swift */,
 				3496955A219B605E00DCFE74 /* PhotoCollectionPickerController.swift */,
@@ -10677,6 +10677,7 @@
 				88D23D2523CEC0C700B0E74B /* CallKitCallUIAdaptee.swift in Sources */,
 				88588D26252E59CE00405414 /* CallService.swift in Sources */,
 				88D23D2623CEC0C700B0E74B /* CallUIAdapter.swift in Sources */,
+				4C21D5D8223AC60F00EF8A77 /* CameraCaptureSession.swift in Sources */,
 				4C46361122EB98EC00185951 /* CameraFirstCaptureSendFlow.swift in Sources */,
 				4CA46F4C219CCC630038ABDE /* CaptionView.swift in Sources */,
 				34546F502649989D007C4958 /* ChatColorViewController.swift in Sources */,
@@ -11071,7 +11072,6 @@
 				88D1BCBB24F73C15009A1738 /* PhoneNumberDiscoverabilitySettingsTableViewController.swift in Sources */,
 				88D1BCB924F73C05009A1738 /* PhoneNumberSharingSettingsTableViewController.swift in Sources */,
 				4C5250D221E7BD7D00CE3D95 /* PhoneNumberValidator.swift in Sources */,
-				4C21D5D8223AC60F00EF8A77 /* PhotoCapture.swift in Sources */,
 				E44AD4E624E98F440035D7B8 /* PhotoCaptureDismiss.swift in Sources */,
 				4CA485BB2232339F004B9E7D /* PhotoCaptureViewController.swift in Sources */,
 				3496955D219B605E00DCFE74 /* PhotoCollectionPickerController.swift in Sources */,
diff --git a/Signal/src/ViewControllers/Photos/PhotoCapture.swift b/Signal/src/ViewControllers/Photos/CameraCaptureSession.swift
similarity index 50%
rename from Signal/src/ViewControllers/Photos/PhotoCapture.swift
rename to Signal/src/ViewControllers/Photos/CameraCaptureSession.swift
index 1096c179d00..baea31f4e2d 100644
--- a/Signal/src/ViewControllers/Photos/PhotoCapture.swift
+++ b/Signal/src/ViewControllers/Photos/CameraCaptureSession.swift
@@ -9,6 +9,7 @@ import CoreServices
 import Foundation
 import SignalCoreKit
 import SignalMessaging
+import SignalUI
 import UIKit
 
 enum PhotoCaptureError: Error {
@@ -31,147 +32,78 @@ extension PhotoCaptureError: LocalizedError, UserErrorDescriptionProvider {
     }
 }
 
-protocol PhotoCaptureDelegate: AnyObject {
+protocol CameraCaptureSessionDelegate: AnyObject {
 
-    // MARK: Still Photo
-
-    func photoCaptureDidStart(_ photoCapture: PhotoCapture)
-    func photoCapture(_ photoCapture: PhotoCapture, didFinishProcessing attachment: SignalAttachment)
-    func photoCapture(_ photoCapture: PhotoCapture, didFailProcessing error: Error)
+    func cameraCaptureSessionDidStart(_ session: CameraCaptureSession)
+    func cameraCaptureSession(_ session: CameraCaptureSession, didFinishProcessing attachment: SignalAttachment)
+    func cameraCaptureSession(_ session: CameraCaptureSession, didFailWith error: Error)
 
     // MARK: Video
 
-    func photoCaptureWillBeginRecording(_ photoCapture: PhotoCapture)
-    func photoCaptureDidBeginRecording(_ photoCapture: PhotoCapture)
-    func photoCaptureDidFinishRecording(_ photoCapture: PhotoCapture)
-    func photoCaptureDidCancelRecording(_ photoCapture: PhotoCapture)
+    func cameraCaptureSessionWillStartVideoRecording(_ session: CameraCaptureSession)
+    func cameraCaptureSessionDidStartVideoRecording(_ session: CameraCaptureSession)
+    func cameraCaptureSessionDidStopVideoRecording(_ session: CameraCaptureSession)
+    func cameraCaptureSession(_ session: CameraCaptureSession, videoRecordingDurationChanged duration: TimeInterval)
 
     // MARK: Utility
 
-    func photoCapture(_ photoCapture: PhotoCapture, didChangeOrientation: AVCaptureVideoOrientation)
-    func photoCapture(_ photoCapture: PhotoCapture, didChangeVideoZoomFactor: CGFloat, forCameraPosition: AVCaptureDevice.Position)
-    func photoCaptureCanCaptureMoreItems(_ photoCapture: PhotoCapture) -> Bool
-    func photoCaptureDidTryToCaptureTooMany(_ photoCapture: PhotoCapture)
+    func cameraCaptureSession(_ session: CameraCaptureSession, didChangeOrientation: AVCaptureVideoOrientation)
+    func cameraCaptureSession(_ session: CameraCaptureSession, didChangeZoomFactor: CGFloat, forCameraPosition: AVCaptureDevice.Position)
+    func cameraCaptureSessionCanCaptureMoreItems(_ session: CameraCaptureSession) -> Bool
+    func photoCaptureDidTryToCaptureTooMany(_ session: CameraCaptureSession)
     var zoomScaleReferenceDistance: CGFloat? { get }
 
     func beginCaptureButtonAnimation(_ duration: TimeInterval)
     func endCaptureButtonAnimation(_ duration: TimeInterval)
 
-    func photoCapture(_ photoCapture: PhotoCapture, didCompleteFocusing focusPoint: CGPoint)
+    func cameraCaptureSession(_ session: CameraCaptureSession, didFinishFocusingAt focusPoint: CGPoint)
 }
 
 // MARK: -
 
-class PhotoCapture: NSObject {
+class CameraCaptureSession: NSObject {
 
-    weak var delegate: PhotoCaptureDelegate?
+    private weak var delegate: CameraCaptureSessionDelegate?
 
     // There can only ever be one `CapturePreviewView` per AVCaptureSession
-    lazy private(set) var previewView = CapturePreviewView(session: session)
-
-    fileprivate static let sessionQueue = DispatchQueue(label: "PhotoCapture.sessionQueue")
-    private var sessionQueue: DispatchQueue { PhotoCapture.sessionQueue }
-
-    private var currentCaptureInput: AVCaptureDeviceInput?
-    private let captureOutput: CaptureOutput
-    private var captureDevice: AVCaptureDevice? {
-        return currentCaptureInput?.device
-    }
-    private(set) var desiredPosition: AVCaptureDevice.Position = .back
-
-    private let recordingAudioActivity = AudioActivity(audioDescription: "PhotoCapture", behavior: .playAndRecord)
-
-    var focusObservation: NSKeyValueObservation?
-
-    override init() {
-        self.session = AVCaptureSession()
-        self.captureOutput = CaptureOutput(session: session)
-    }
-
-    deinit {
-        self.motionManager?.stopAccelerometerUpdates()
-    }
-
-    func didCompleteFocusing() {
-        Logger.debug("")
-        guard let currentCaptureInput = currentCaptureInput else {
-            return
-        }
-
-        let focusPoint = currentCaptureInput.device.focusPointOfInterest
-
-        DispatchQueue.main.async {
-            self.delegate?.photoCapture(self, didCompleteFocusing: focusPoint)
-        }
-    }
+    lazy var previewView = CapturePreviewView(session: avCaptureSession)
 
-    private var audioDeviceInput: AVCaptureDeviceInput?
+    let avCaptureSession = AVCaptureSession()
+    private static let sessionQueue = DispatchQueue(label: "CameraCaptureSession")
+    private var sessionQueue: DispatchQueue { CameraCaptureSession.sessionQueue }
 
-    // MARK: - Public
+    // Separate session for capturing audio is necessary to eliminate
+    // video stream stutter when audio connection is established.
+    private let audioCaptureSession = AVCaptureSession()
+    private var audioCaptureInput: AVCaptureDeviceInput?
 
-    var flashMode: AVCaptureDevice.FlashMode {
-        return captureOutput.flashMode
+    private var videoCaptureInput: AVCaptureDeviceInput?
+    private var videoCaptureDevice: AVCaptureDevice? {
+        return videoCaptureInput?.device
     }
 
-    let session: AVCaptureSession
-
-    func startAudioCapture() -> Bool {
-        assertIsOnSessionQueue()
+    private let photoCapture = PhotoCapture()
+    private let videoCapture = VideoCapture()
 
-        // This check will fail if we do not have recording permissions.
-        guard audioSession.startAudioActivity(recordingAudioActivity) else {
-            Logger.warn("Unable to start recording audio activity!")
-            return false
-        }
+    init(delegate: CameraCaptureSessionDelegate) {
+        self.delegate = delegate
 
-        guard let audioDevice = AVCaptureDevice.default(for: .audio) else {
-            Logger.warn("Missing audio capture device!")
-            return false
-        }
-
-        do {
-            let audioDeviceInput = try AVCaptureDeviceInput(device: audioDevice)
-
-            guard session.canAddInput(audioDeviceInput) else {
-                owsFailDebug("Could not add audio device input to the session")
-                return false
-            }
-
-            session.addInput(audioDeviceInput)
-            self.audioDeviceInput = audioDeviceInput
-        } catch let error {
-            Logger.warn("Failed to create audioDeviceInput: \(error)")
-            return false
-        }
-
-        return true
-    }
-
-    func stopAudioCapture() {
-        assertIsOnSessionQueue()
+        super.init()
 
-        self.session.beginConfiguration()
-        defer { self.session.commitConfiguration() }
+        avCaptureSession.automaticallyConfiguresApplicationAudioSession = false
+        avCaptureSession.usesApplicationAudioSession = true
 
-        guard let audioDeviceInput = self.audioDeviceInput else {
-            Logger.warn("audioDeviceInput was nil - recording permissions may have been disabled?")
-            return
-        }
+        audioCaptureSession.automaticallyConfiguresApplicationAudioSession = false
+        audioCaptureSession.usesApplicationAudioSession = true
 
-        session.removeInput(audioDeviceInput)
-        self.audioDeviceInput = nil
-        audioSession.endAudioActivity(recordingAudioActivity)
+        videoCapture.delegate = self
     }
 
-    func updateVideoPreviewConnection(toOrientation orientation: AVCaptureVideoOrientation) {
-        guard let videoConnection = previewView.previewLayer.connection else {
-            Logger.info("previewView hasn't completed setup yet.")
-            return
-        }
-        videoConnection.videoOrientation = orientation
+    deinit {
+        motionManager?.stopAccelerometerUpdates()
     }
 
-    func prepareVideoCapture() -> Promise<Void> {
+    func prepare() -> Promise<Void> {
         AssertIsOnMainThread()
         guard !Platform.isSimulator else {
             // Trying to actually set up the capture session will fail on a simulator
@@ -181,72 +113,62 @@ class PhotoCapture: NSObject {
         }
 
         // If the session is already running, no need to do anything.
-        guard !self.session.isRunning else { return Promise.value(()) }
+        guard !avCaptureSession.isRunning else { return Promise.value(()) }
 
         let initialCaptureOrientation = beginObservingOrientationChanges()
 
         return sessionQueue.async(.promise) { [weak self] in
-            guard let self = self else { return }
+            guard let self else { return }
 
-            self.session.beginConfiguration()
-            defer { self.session.commitConfiguration() }
+            self.avCaptureSession.beginConfiguration()
+            defer { self.avCaptureSession.commitConfiguration() }
 
             self.captureOrientation = initialCaptureOrientation ?? self.captureOrientation
-            self.session.sessionPreset = .high
+            self.avCaptureSession.sessionPreset = .high
 
-            try self.reconfigureCaptureInput()
+            // 1. Reconfigure which camera to use.
+            try self.reconfigureVideoCaptureInput()
 
-            guard let photoOutput = self.captureOutput.photoOutput else {
-                owsFailDebug("Missing photoOutput.")
+            // 2. Add photo output (AVCapturePhotoOutput).
+            let photoOutput = self.photoCapture.avCaptureOutput
+            guard self.avCaptureSession.canAddOutput(photoOutput) else {
+                owsFailDebug("Could not add AVCapturePhotoOutput.")
                 throw PhotoCaptureError.initializationFailed
             }
-
-            guard self.session.canAddOutput(photoOutput) else {
-                owsFailDebug("!canAddOutput(photoOutput).")
+            self.avCaptureSession.addOutput(photoOutput)
+            // Do not set `preferredVideoStabilizationMode` - doing so causes
+            // recording latency and results in last ~1.5 seconds of video not being written.
+
+            // 3. Add outputs for video (AVCaptureVideoDataOutput and AVCaptureAudioDataOutput).
+            let videoDataOutput = self.videoCapture.videoDataOutput
+            guard self.avCaptureSession.canAddOutput(videoDataOutput) else {
+                owsFailDebug("Could not add AVCaptureVideoDataOutput.")
                 throw PhotoCaptureError.initializationFailed
             }
-            self.session.addOutput(photoOutput)
+            self.avCaptureSession.addOutput(videoDataOutput)
 
-            if let connection = photoOutput.connection(with: .video) {
-                if connection.isVideoStabilizationSupported {
-                    connection.preferredVideoStabilizationMode = .auto
-                }
-            }
-
-            let videoDataOutput = self.captureOutput.videoDataOutput
-            guard self.session.canAddOutput(videoDataOutput) else {
-                owsFailDebug("!canAddOutput(videoDataOutput).")
-                throw PhotoCaptureError.initializationFailed
-            }
-            self.session.addOutput(videoDataOutput)
-            guard let connection = videoDataOutput.connection(with: .video) else {
-                owsFailDebug("Missing videoDataOutput.connection.")
-                throw PhotoCaptureError.initializationFailed
-            }
-            if connection.isVideoStabilizationSupported {
-                connection.preferredVideoStabilizationMode = .auto
-            }
-
-            let audioDataOutput = self.captureOutput.audioDataOutput
-            if self.session.canAddOutput(audioDataOutput) {
-                self.session.addOutput(audioDataOutput)
+            let audioDataOutput = self.videoCapture.audioDataOutput
+            if self.audioCaptureSession.canAddOutput(audioDataOutput) {
+                self.audioCaptureSession.addOutput(audioDataOutput)
             } else {
-                owsFailDebug("couldn't add audioDataOutput")
+                owsFailDebug("Could not add AVCaptureAudioDataOutput.")
             }
         }
     }
 
     @discardableResult
-    func stopCapture() -> Guarantee<Void> {
-        sessionQueue.async(.promise) { [session] in
-            session.stopRunning()
+    func stop() -> Guarantee<Void> {
+        sessionQueue.async(.promise) { [avCaptureSession, audioCaptureSession] in
+            avCaptureSession.stopRunning()
+            audioCaptureSession.stopRunning()
         }
     }
 
     @discardableResult
-    func resumeCapture() -> Guarantee<Void> {
-        sessionQueue.async(.promise) { [session] in
-            session.startRunning()
+    func resume() -> Guarantee<Void> {
+        sessionQueue.async(.promise) { [avCaptureSession, audioCaptureSession] in
+            avCaptureSession.startRunning()
+            audioCaptureSession.startRunning()
         }
     }
 
@@ -254,56 +176,30 @@ class PhotoCapture: NSObject {
         assertOnQueue(sessionQueue)
     }
 
-    func switchCameraPosition() -> Promise<Void> {
-        AssertIsOnMainThread()
-        let newPosition: AVCaptureDevice.Position
-        switch desiredPosition {
-        case .front:
-            newPosition = .back
-        case .back:
-            newPosition = .front
-        case .unspecified:
-            newPosition = .front
-        @unknown default:
-            owsFailDebug("Unexpected enum value.")
-            newPosition = .front
-        }
-        desiredPosition = newPosition
-
-        return sessionQueue.async(.promise) { [weak self] in
-            guard let self = self else { return }
-
-            self.session.beginConfiguration()
-            defer { self.session.commitConfiguration() }
-            try self.reconfigureCaptureInput()
-        }
-    }
-
     // This method should be called on the serial queue, and between calls to session.beginConfiguration/commitConfiguration
-    func reconfigureCaptureInput() throws {
+    func reconfigureVideoCaptureInput() throws {
         assertIsOnSessionQueue()
 
-        let avCaptureDevicePosition = desiredPosition
-        let avCaptureDeviceType = avCaptureDeviceType(forCameraSystem: bestAvailableCameraSystem(forPosition: avCaptureDevicePosition))
-
-        guard let device = captureOutput.videoDevice(for: avCaptureDeviceType, position: avCaptureDevicePosition) else {
+        guard let device = defaultVideoCaptureDevice(forPosition: desiredPosition) else {
             throw PhotoCaptureError.assertionError(description: description)
         }
 
         let newInput = try AVCaptureDeviceInput(device: device)
 
-        if let oldInput = self.currentCaptureInput {
-            session.removeInput(oldInput)
+        if let oldInput = videoCaptureInput {
+            avCaptureSession.removeInput(oldInput)
             NotificationCenter.default.removeObserver(self, name: .AVCaptureDeviceSubjectAreaDidChange, object: oldInput.device)
         }
-        session.addInput(newInput)
+        avCaptureSession.addInput(newInput)
         NotificationCenter.default.addObserver(self, selector: #selector(subjectAreaDidChange), name: .AVCaptureDeviceSubjectAreaDidChange, object: newInput.device)
 
-        if let focusObservation = focusObservation {
+        if let focusObservation {
             focusObservation.invalidate()
         }
-        self.focusObservation = newInput.observe(\.device.isAdjustingFocus,
-                                                  options: [.old, .new]) { [weak self] _, change in
+        focusObservation = newInput.observe(
+            \.device.isAdjustingFocus,
+             options: [.old, .new]
+        ) { [weak self] _, change in
             guard let self = self else { return }
 
             guard let oldValue = change.oldValue else {
@@ -319,7 +215,7 @@ class PhotoCapture: NSObject {
             }
         }
 
-        currentCaptureInput = newInput
+        videoCaptureInput = newInput
 
         // Camera by default has zoom factor of 1, which would be UW camera on triple camera systems, but default camera in the UI is "wide".
         // Also it is necessary to reset camera to "1x" when switching between front and rear to match Camera app behavior.
@@ -328,65 +224,84 @@ class PhotoCapture: NSObject {
         resetFocusAndExposure()
     }
 
-    func switchFlashMode() -> Guarantee<Void> {
+    // MARK: - Flash
+
+    var flashMode: AVCaptureDevice.FlashMode { photoCapture.flashMode }
+
+    func toggleFlashMode() -> Guarantee<Void> {
         return sessionQueue.async(.promise) {
-            switch self.captureOutput.flashMode {
+            switch self.photoCapture.flashMode {
             case .auto:
                 Logger.debug("new flashMode: on")
-                self.captureOutput.flashMode = .on
+                self.photoCapture.flashMode = .on
             case .on:
                 Logger.debug("new flashMode: off")
-                self.captureOutput.flashMode = .off
+                self.photoCapture.flashMode = .off
             case .off:
                 Logger.debug("new flashMode: auto")
-                self.captureOutput.flashMode = .auto
+                self.photoCapture.flashMode = .auto
             @unknown default:
-                owsFailDebug("unknown flashMode: \(self.captureOutput.flashMode)")
-                self.captureOutput.flashMode = .auto
+                owsFailDebug("unknown flashMode: \(self.photoCapture.flashMode)")
+                self.photoCapture.flashMode = .auto
             }
         }
     }
 
-    func focus(with focusMode: AVCaptureDevice.FocusMode,
-               exposureMode: AVCaptureDevice.ExposureMode,
-               at devicePoint: CGPoint,
-               monitorSubjectAreaChange: Bool) {
-        sessionQueue.async {
-            Logger.debug("focusMode: \(focusMode), exposureMode: \(exposureMode), devicePoint: \(devicePoint), monitorSubjectAreaChange:\(monitorSubjectAreaChange)")
-            guard let device = self.captureDevice else {
-                if !Platform.isSimulator {
-                    owsFailDebug("device was unexpectedly nil")
-                }
-                return
-            }
-            do {
-                try device.lockForConfiguration()
+    // MARK: - Focusing
 
-                // Setting (focus/exposure)PointOfInterest alone does not initiate a (focus/exposure) operation.
-                // Call set(Focus/Exposure)Mode() to apply the new point of interest.
-                if device.isFocusPointOfInterestSupported && device.isFocusModeSupported(focusMode) {
-                    device.focusPointOfInterest = devicePoint
-                    device.focusMode = focusMode
-                }
+    var focusObservation: NSKeyValueObservation?
 
-                if device.isExposurePointOfInterestSupported && device.isExposureModeSupported(exposureMode) {
-                    device.exposurePointOfInterest = devicePoint
-                    device.exposureMode = exposureMode
+    func focus(
+        with focusMode: AVCaptureDevice.FocusMode,
+        exposureMode: AVCaptureDevice.ExposureMode,
+        at devicePoint: CGPoint,
+        monitorSubjectAreaChange: Bool) {
+            sessionQueue.async {
+                Logger.debug("focusMode: \(focusMode), exposureMode: \(exposureMode), devicePoint: \(devicePoint), monitorSubjectAreaChange:\(monitorSubjectAreaChange)")
+                guard let device = self.videoCaptureDevice else {
+                    if !Platform.isSimulator {
+                        owsFailDebug("device was unexpectedly nil")
+                    }
+                    return
                 }
+                do {
+                    try device.lockForConfiguration()
+
+                    // Setting (focus/exposure)PointOfInterest alone does not initiate a (focus/exposure) operation.
+                    // Call set(Focus/Exposure)Mode() to apply the new point of interest.
+                    if device.isFocusPointOfInterestSupported && device.isFocusModeSupported(focusMode) {
+                        device.focusPointOfInterest = devicePoint
+                        device.focusMode = focusMode
+                    }
 
-                device.isSubjectAreaChangeMonitoringEnabled = monitorSubjectAreaChange
-                device.unlockForConfiguration()
-            } catch {
-                owsFailDebug("error: \(error)")
+                    if device.isExposurePointOfInterestSupported && device.isExposureModeSupported(exposureMode) {
+                        device.exposurePointOfInterest = devicePoint
+                        device.exposureMode = exposureMode
+                    }
+
+                    device.isSubjectAreaChangeMonitoringEnabled = monitorSubjectAreaChange
+                    device.unlockForConfiguration()
+                } catch {
+                    owsFailDebug("error: \(error)")
+                }
             }
         }
-    }
 
     func resetFocusAndExposure() {
         let devicePoint = CGPoint(x: 0.5, y: 0.5)
         focus(with: .continuousAutoFocus, exposureMode: .continuousAutoExposure, at: devicePoint, monitorSubjectAreaChange: false)
     }
 
+    func didCompleteFocusing() {
+        Logger.debug("")
+        guard let videoCaptureDevice else { return }
+
+        let focusPoint = videoCaptureDevice.focusPointOfInterest
+        DispatchQueue.main.async {
+            self.delegate?.cameraCaptureSession(self, didFinishFocusingAt: focusPoint)
+        }
+    }
+
     @objc
     private func subjectAreaDidChange(notification: NSNotification) {
         resetFocusAndExposure()
@@ -408,11 +323,18 @@ class PhotoCapture: NSObject {
 
     private var motionManager: CMMotionManager?
 
+    func updateVideoPreviewConnection(toOrientation orientation: AVCaptureVideoOrientation) {
+        guard let videoConnection = previewView.previewLayer.connection else {
+            Logger.info("previewView hasn't completed setup yet.")
+            return
+        }
+        videoConnection.videoOrientation = orientation
+    }
+
     // Outputs initial orientation.
     private func beginObservingOrientationChanges() -> AVCaptureVideoOrientation? {
-        guard self.motionManager == nil else {
-            return nil
-        }
+        guard motionManager == nil else { return nil }
+
         let motionManager = CMMotionManager()
         motionManager.accelerometerUpdateInterval = 0.2
         motionManager.gyroUpdateInterval = 0.2
@@ -443,19 +365,72 @@ class PhotoCapture: NSObject {
     }
 
     private func updateOrientation(_ orientation: AVCaptureVideoOrientation) {
-        self.sessionQueue.async {
+        sessionQueue.async {
             guard orientation != self.captureOrientation else {
                 return
             }
             self.captureOrientation = orientation
 
             DispatchQueue.main.async {
-                self.delegate?.photoCapture(self, didChangeOrientation: orientation)
+                self.delegate?.cameraCaptureSession(self, didChangeOrientation: orientation)
+            }
+        }
+    }
+
+    // MARK: - Camera Device Information
+
+    private lazy var availableRearVideoCaptureDeviceMap: [AVCaptureDevice.DeviceType: AVCaptureDevice] = {
+        return CameraCaptureSession.availableVideoCaptureDevices(forPosition: .back)
+    }()
+
+    private lazy var availableFrontVideoCaptureDeviceMap: [AVCaptureDevice.DeviceType: AVCaptureDevice] = {
+        return CameraCaptureSession.availableVideoCaptureDevices(forPosition: .front)
+    }()
+
+    private class func availableVideoCaptureDevices(forPosition position: AVCaptureDevice.Position) -> [AVCaptureDevice.DeviceType: AVCaptureDevice] {
+        var queryDeviceTypes: [AVCaptureDevice.DeviceType] = [ .builtInWideAngleCamera, .builtInTelephotoCamera, .builtInDualCamera ]
+        if #available(iOS 13, *) {
+            queryDeviceTypes.append(contentsOf: [ .builtInUltraWideCamera, .builtInDualWideCamera, .builtInTripleCamera ])
+        }
+        let session = AVCaptureDevice.DiscoverySession(deviceTypes: queryDeviceTypes, mediaType: .video, position: position)
+        let deviceMap = session.devices.reduce(into: [AVCaptureDevice.DeviceType: AVCaptureDevice]()) { deviceMap, device in
+            deviceMap[device.deviceType] = device
+        }
+        return deviceMap
+    }
+
+    private func availableVideoCaptureDeviceTypes(forPosition position: AVCaptureDevice.Position) -> [AVCaptureDevice.DeviceType] {
+        switch position {
+        case .front, .unspecified:
+            return Array(availableFrontVideoCaptureDeviceMap.keys)
+
+        case .back:
+            return Array(availableRearVideoCaptureDeviceMap.keys)
+
+        @unknown default:
+            owsFailDebug("Unknown AVCaptureDevice.Position: [\(position)]")
+            return []
+        }
+    }
+
+    private func cameraSwitchOverZoomFactors(forPosition position: AVCaptureDevice.Position) -> [CGFloat] {
+        let deviceMap = position == .front ? availableFrontVideoCaptureDeviceMap : availableRearVideoCaptureDeviceMap
+
+        guard #available(iOS 13, *) else {
+            // No iOS 12 device can have triple camera system.
+            if deviceMap[.builtInDualCamera] != nil {
+                return UIDevice.current.isPlusSizePhone ? [ 2.5 ] : [ 2 ]
             }
+            return []
+        }
+
+        if let multiCameraDevice = deviceMap[.builtInTripleCamera] ?? deviceMap[.builtInDualWideCamera] ?? deviceMap[.builtInDualCamera] {
+            return multiCameraDevice.virtualDeviceSwitchOverVideoZoomFactors.map { CGFloat(truncating: $0) }
         }
+        return []
     }
 
-    // MARK: - Rear Camera Selection
+    // MARK: - Camera Selection
 
     // Order must be the same as it appears in the in-app camera UI.
     enum CameraType: Comparable {
@@ -471,68 +446,98 @@ class PhotoCapture: NSObject {
         case triple     // UW + W + T
     }
 
-    private func availableCameras(forPosition position: AVCaptureDevice.Position) -> [CameraType] {
-        let avTypes = captureOutput.imageOutput.availableDeviceTypes(forPosition: position)
-        var cameras: [CameraType] = []
+    private func availableCameras(forPosition position: AVCaptureDevice.Position) -> Set<CameraType> {
+        let avTypes = availableVideoCaptureDeviceTypes(forPosition: position)
+        var cameras: Set<CameraType> = []
 
         // AVCaptureDevice.DiscoverySession returns devices in an arbitrary order, explicit ordering is required
         if #available(iOS 13, *), avTypes.contains(.builtInUltraWideCamera) {
-            cameras.append(.ultraWide)
+            cameras.insert(.ultraWide)
         }
 
         if avTypes.contains(.builtInWideAngleCamera) {
-            cameras.append(.wideAngle)
+            cameras.insert(.wideAngle)
         }
 
         if avTypes.contains(.builtInTelephotoCamera) {
-            cameras.append(.telephoto)
+            cameras.insert(.telephoto)
         }
 
         return cameras
     }
 
-    private func bestAvailableCameraSystem(forPosition position: AVCaptureDevice.Position) -> CameraSystem {
-        let avTypes = captureOutput.imageOutput.availableDeviceTypes(forPosition: position)
+    private func defaultVideoCaptureDevice(forPosition position: AVCaptureDevice.Position) -> AVCaptureDevice? {
+        guard let devices: [AVCaptureDevice.DeviceType: AVCaptureDevice] = {
+            switch position {
+            case .front, .unspecified:
+                return availableFrontVideoCaptureDeviceMap
+
+            case .back:
+                return availableRearVideoCaptureDeviceMap
+
+            @unknown default:
+                owsFailDebug("Unknown AVCaptureDevice.Position: [\(position)]")
+                return nil
+            }
+        }() else { return nil }
 
-        // No iOS 12 device can have a triple camera system.
         if #available(iOS 13, *) {
-            if avTypes.contains(.builtInTripleCamera) {
-                return .triple
+            if let device = devices[.builtInTripleCamera] {
+                return device
             }
-            if avTypes.contains(.builtInDualWideCamera) {
-                return .dualWide
+            if let device = devices[.builtInDualWideCamera] {
+                return device
             }
         }
-        if avTypes.contains(.builtInDualCamera) {
-            return .dual
+        return devices[.builtInDualCamera] ?? devices[.builtInWideAngleCamera]
+    }
+
+    private(set) var desiredPosition: AVCaptureDevice.Position = .back
+
+    func switchCameraPosition() -> Promise<Void> {
+        AssertIsOnMainThread()
+        let newPosition: AVCaptureDevice.Position
+        switch desiredPosition {
+        case .front:
+            newPosition = .back
+
+        case .back, .unspecified:
+            newPosition = .front
+
+        @unknown default:
+            owsFailDebug("Unexpected enum value.")
+            newPosition = .front
+        }
+        desiredPosition = newPosition
+
+        return sessionQueue.async(.promise) { [weak self] in
+            guard let self = self else { return }
+
+            self.avCaptureSession.beginConfiguration()
+            defer { self.avCaptureSession.commitConfiguration() }
+            try self.reconfigureVideoCaptureInput()
         }
-        return .wide
     }
 
-    private func avCaptureDeviceType(forCameraSystem cameraSystem: CameraSystem) -> AVCaptureDevice.DeviceType {
-        switch cameraSystem {
-        case .wide:
-            return .builtInWideAngleCamera
+    func switchCamera(to camera: CameraType, at position: AVCaptureDevice.Position, animated: Bool) {
+        AssertIsOnMainThread()
 
-        case .dual:
-            return .builtInDualCamera
+        owsAssertDebug(position == desiredPosition, "Attempt to select camera for incorrect position")
 
-        case .dualWide:
-            if #available(iOS 13, *) {
-                return .builtInDualWideCamera
-            }
-            fallthrough
+        let cameraZoomFactorMap = cameraZoomFactorMap(forPosition: position)
+        guard let visibleZoomFactor = cameraZoomFactorMap[camera] else {
+            owsFailDebug("Requested an unsupported device type")
+            return
+        }
 
-        case .triple:
-            if #available(iOS 13, *) {
-                return .builtInTripleCamera
-            }
-            fallthrough
+        var zoomFactor = visibleZoomFactor / cameraZoomFactorMultiplier(forPosition: position)
 
-        default:
-            owsFailDebug("Unsupported camera system.")
-            return .builtInWideAngleCamera
+        // Tap on 1x changes zoom to 2x if there's only one rear camera available.
+        let availableCameras = availableCameras(forPosition: position)
+        if availableCameras.count == 1, zoomFactor == videoCaptureDevice?.videoZoomFactor {
+            zoomFactor *= 2
         }
+        updateZoomFactor(zoomFactor, animated: animated)
     }
 
     // MARK: - Zoom
@@ -553,8 +558,8 @@ class PhotoCapture: NSObject {
     }
 
     func cameraZoomFactorMap(forPosition position: AVCaptureDevice.Position) -> [CameraType: CGFloat] {
-        let zoomFactors = captureOutput.imageOutput.cameraSwitchOverZoomFactors(forPosition: position)
-        let avTypes = captureOutput.imageOutput.availableDeviceTypes(forPosition: position)
+        let zoomFactors = cameraSwitchOverZoomFactors(forPosition: position)
+        let avTypes = availableVideoCaptureDeviceTypes(forPosition: position)
         let cameraZoomFactorMultiplier = cameraZoomFactorMultiplier(forPosition: position)
 
         var cameraMap: [CameraType: CGFloat] = [:]
@@ -582,27 +587,6 @@ class PhotoCapture: NSObject {
         return 1
     }
 
-    func switchCamera(to camera: CameraType, at position: AVCaptureDevice.Position, animated: Bool) {
-        AssertIsOnMainThread()
-
-        owsAssertDebug(position == desiredPosition, "Attempt to select camera for incorrect position")
-
-        let cameraZoomFactorMap = cameraZoomFactorMap(forPosition: position)
-        guard let visibleZoomFactor = cameraZoomFactorMap[camera] else {
-            owsFailDebug("Requested an unsupported device type")
-            return
-        }
-
-        var zoomFactor = visibleZoomFactor / cameraZoomFactorMultiplier(forPosition: position)
-
-        // Tap on 1x changes zoom to 2x if there's only one rear camera available.
-        let availableCameras = availableCameras(forPosition: position)
-        if availableCameras.count == 1, let currentZoomFactor = captureDevice?.videoZoomFactor, currentZoomFactor == zoomFactor {
-            zoomFactor *= 2
-        }
-        updateZoomFactor(zoomFactor, animated: animated)
-    }
-
     func changeVisibleZoomFactor(to visibleZoomFactor: CGFloat, animated: Bool) {
         let zoomFactor = visibleZoomFactor / cameraZoomFactorMultiplier(forPosition: desiredPosition)
         updateZoomFactor(zoomFactor, animated: animated)
@@ -610,8 +594,8 @@ class PhotoCapture: NSObject {
 
     private func updateZoomFactor(_ zoomFactor: CGFloat, animated: Bool) {
         sessionQueue.async { [weak self] in
-            guard let self = self else { return }
-            guard let captureDevice = self.captureDevice else {
+            guard let self else { return }
+            guard let captureDevice = self.videoCaptureDevice else {
                 owsFailDebug("captureDevice was unexpectedly nil")
                 return
             }
@@ -638,8 +622,8 @@ class PhotoCapture: NSObject {
     func updateZoom(alpha: CGFloat) {
         owsAssertDebug(alpha >= 0 && alpha <= 1)
         sessionQueue.async { [weak self] in
-            guard let self = self else { return }
-            guard let captureDevice = self.captureDevice else {
+            guard let self else { return }
+            guard let captureDevice = self.videoCaptureDevice else {
                 owsFailDebug("captureDevice was unexpectedly nil")
                 return
             }
@@ -653,8 +637,8 @@ class PhotoCapture: NSObject {
 
     func beginPinchZoom() {
         sessionQueue.async { [weak self] in
-            guard let self = self else { return }
-            guard let captureDevice = self.captureDevice else {
+            guard let self else { return }
+            guard let captureDevice = self.videoCaptureDevice else {
                 owsFailDebug("captureDevice was unexpectedly nil")
                 return
             }
@@ -666,8 +650,8 @@ class PhotoCapture: NSObject {
 
     func updatePinchZoom(withScale scale: CGFloat) {
         sessionQueue.async { [weak self] in
-            guard let self = self else { return }
-            guard let captureDevice = self.captureDevice else {
+            guard let self else { return }
+            guard let captureDevice = self.videoCaptureDevice else {
                 owsFailDebug("captureDevice was unexpectedly nil")
                 return
             }
@@ -679,8 +663,8 @@ class PhotoCapture: NSObject {
 
     func completePinchZoom(withScale scale: CGFloat) {
         sessionQueue.async { [weak self] in
-            guard let self = self else { return }
-            guard let captureDevice = self.captureDevice else {
+            guard let self else { return }
+            guard let captureDevice = self.videoCaptureDevice else {
                 owsFailDebug("captureDevice was unexpectedly nil")
                 return
             }
@@ -713,41 +697,45 @@ class PhotoCapture: NSObject {
             let visibleZoomFactor = clampedZoomFactor * zoomFactorMultiplier
             DispatchQueue.main.async { [weak self] in
                 guard let self = self else { return }
-                self.delegate?.photoCapture(self, didChangeVideoZoomFactor: visibleZoomFactor, forCameraPosition: devicePosition)
+                self.delegate?.cameraCaptureSession(self, didChangeZoomFactor: visibleZoomFactor, forCameraPosition: devicePosition)
             }
         } catch {
             owsFailDebug("error: \(error)")
         }
     }
 
-    // MARK: - Photo
+    // MARK: - Photo Capture
 
     private func takePhoto() {
         Logger.verbose("")
         AssertIsOnMainThread()
 
-        guard let delegate = delegate else { return }
-        guard delegate.photoCaptureCanCaptureMoreItems(self) else {
+        guard let delegate else { return }
+
+        guard delegate.cameraCaptureSessionCanCaptureMoreItems(self) else {
             delegate.photoCaptureDidTryToCaptureTooMany(self)
             return
         }
 
-        let captureRect = captureOutputPhotoRect
-        delegate.photoCaptureDidStart(self)
+        ImpactHapticFeedback.impactOccured(style: .medium)
+
+        let previewLayer = previewView.previewLayer
+        let captureRect = previewLayer.metadataOutputRectConverted(fromLayerRect: previewLayer.bounds)
+        delegate.cameraCaptureSessionDidStart(self)
         sessionQueue.async {
-            self.captureOutput.takePhoto(delegate: self, captureRect: captureRect)
+            self.photoCapture.takePhoto(delegate: self, captureOrientation: self.captureOrientation, captureRect: captureRect)
         }
     }
 
-    // MARK: - Video
+    // MARK: - Video Capture
 
     private enum VideoRecordingState: Equatable {
-        case stopped
-        case starting
-        case recording
+        case ready
+        case started
         case stopping
+        case canceling
     }
-    private var _videoRecordingState: VideoRecordingState = .stopped
+    private var _videoRecordingState: VideoRecordingState = .ready
     private var videoRecordingState: VideoRecordingState {
         get {
             AssertIsOnMainThread()
@@ -760,136 +748,252 @@ class PhotoCapture: NSObject {
         }
     }
 
-    private func beginMovieCapture() {
+    private func videoAspectRatio() -> CGFloat {
+        AssertIsOnMainThread()
+        let size = UIScreen.main.bounds.size
+        let screenAspect: CGFloat
+        if size.width == 0 || size.height == 0 {
+            screenAspect = 0
+        } else if size.width > size.height {
+            screenAspect = size.height / size.width
+        } else {
+            screenAspect = size.width / size.height
+        }
+        return screenAspect.clamp(9/16, 3/4)
+    }
+
+    private func startVideoRecording() {
         AssertIsOnMainThread()
         Logger.verbose("")
 
+        guard videoRecordingState == .ready else {
+            owsFailBeta("Invalid recording state: \(videoRecordingState)")
+            return
+        }
+
         guard let delegate = delegate else { return }
-        guard delegate.photoCaptureCanCaptureMoreItems(self) else {
+        guard delegate.cameraCaptureSessionCanCaptureMoreItems(self) else {
             delegate.photoCaptureDidTryToCaptureTooMany(self)
             return
         }
 
-        owsAssertDebug(videoRecordingState == .stopped)
+        videoRecordingState = .started
+        delegate.cameraCaptureSessionWillStartVideoRecording(self)
 
-        let aspectRatio = captureOutputAspectRatio
-        firstly(on: captureOutput.movieRecordingQueue) { () -> Promise<Void> in
-            let movieRecordingBox = self.captureOutput.newMovieRecordingBox()
-            return firstly(on: self.sessionQueue) {
-                self.session.beginConfiguration()
-                defer { self.session.commitConfiguration() }
+        let aspectRatio = videoAspectRatio()
+        let videoCapture = videoCapture
+        sessionQueue.async {
+            self.setTorchMode(self.flashMode.toTorchMode)
 
-                self.setTorchMode(self.flashMode.toTorchMode)
+            let audioCaptureStarted = self.startAudioCapture()
+            let captureOrientation = self.captureOrientation
 
-                let audioCaptureStartedSuccessfully = self.startAudioCapture()
-                return try self.captureOutput.beginMovie(
-                    delegate: self,
+            do {
+                try videoCapture.beginRecording(
+                    captureOrientation: captureOrientation,
                     aspectRatio: aspectRatio,
-                    includeAudio: audioCaptureStartedSuccessfully
+                    includeAudio: audioCaptureStarted
                 )
-            }.done(on: self.captureOutput.movieRecordingQueue) { movieRecording in
-                movieRecordingBox.set(movieRecording)
-            }.done {
-                // Makes sure that user hasn't stopped recording while recording was being started.
-                guard self.videoRecordingState == .starting else {
-                    throw PhotoCaptureError.invalidVideo
+            } catch {
+                DispatchQueue.main.async {
+                    self.handleVideoCaptureError(error)
                 }
-
-                self.videoRecordingState = .recording
-                self.delegate?.photoCaptureDidBeginRecording(self)
+                self.cleanUpAfterVideoRecording()
             }
-        }.catch { error in
-            self.handleMovieCaptureError(error)
         }
-
-        videoRecordingState = .starting
-        delegate.photoCaptureWillBeginRecording(self)
     }
 
-    private func completeMovieCapture() {
-        // User has stopped recording before the it has actually started.
-        // Treat this as canceled recording.
-        if videoRecordingState == .starting {
-            cancelMovieCapture()
+    private func stopVideoRecording() {
+        guard videoRecordingState == .started else {
+            owsFailBeta("Invalid recording state: \(videoRecordingState)")
             return
         }
 
         Logger.verbose("")
-        BenchEventStart(title: "Movie Processing", eventId: "Movie Processing")
+        BenchEventStart(title: "Video Processing", eventId: "Video Processing")
 
-        owsAssertDebug(videoRecordingState == .recording)
         videoRecordingState = .stopping
 
-        firstly(on: captureOutput.movieRecordingQueue) {
-            self.captureOutput.completeMovie(delegate: self)
-        }.done(on: DispatchQueue.main) {
-            AssertIsOnMainThread()
+        videoCapture.stopRecording()
+    }
 
-            guard self.videoRecordingState == .stopping else {
-                throw PhotoCaptureError.invalidVideo
-            }
+    private func cancelVideoRecording() {
+        guard videoRecordingState == .started else {
+            owsFailBeta("Invalid recording state: \(videoRecordingState)")
+            return
+        }
 
-            self.sessionQueue.async {
-                self.setTorchMode(.off)
-                self.stopAudioCapture()
-            }
+        Logger.verbose("")
 
-            // Inform UI that capture is stopping.
-            self.videoRecordingState = .stopped
-            self.delegate?.photoCaptureDidFinishRecording(self)
-        }.catch { error in
-            self.handleMovieCaptureError(error)
+        videoRecordingState = .canceling
+        videoCapture.stopRecording()
+    }
+
+    private func handleVideoRecording(at outputUrl: URL) {
+        AssertIsOnMainThread()
+
+        guard let delegate else { return }
+
+        guard OWSMediaUtils.isValidVideo(path: outputUrl.path) else {
+            return handleVideoCaptureError(PhotoCaptureError.invalidVideo)
+        }
+        guard let dataSource = try? DataSourcePath.dataSource(with: outputUrl, shouldDeleteOnDeallocation: true) else {
+            return handleVideoCaptureError(PhotoCaptureError.captureFailed)
         }
+
+        let attachment = SignalAttachment.attachment(dataSource: dataSource, dataUTI: kUTTypeMPEG4 as String)
+        BenchEventComplete(eventId: "Video Processing")
+        delegate.cameraCaptureSession(self, didFinishProcessing: attachment)
     }
 
-    private func handleMovieCaptureError(_ error: Error) {
+    private func handleVideoCaptureError(_ error: Error) {
         AssertIsOnMainThread()
+
         if case PhotoCaptureError.invalidVideo = error {
             Logger.warn("Error: \(error)")
         } else {
             owsFailDebug("Error: \(error)")
         }
-        self.sessionQueue.async {
-            self.setTorchMode(.off)
-            self.stopAudioCapture()
+
+        delegate?.cameraCaptureSession(self, didFailWith: error)
+    }
+
+    private func cleanUpAfterVideoRecording() {
+        Logger.debug("")
+
+        assertIsOnSessionQueue()
+
+        setTorchMode(.off)
+        stopAudioCapture()
+
+        DispatchQueue.main.async {
+            self.videoRecordingState = .ready
+            self.delegate?.cameraCaptureSessionDidStopVideoRecording(self)
         }
-        self.videoRecordingState = .stopped
-        self.delegate?.photoCapture(self, didFailProcessing: error)
     }
 
-    private func cancelMovieCapture() {
-        Logger.verbose("")
+    private func setTorchMode(_ mode: AVCaptureDevice.TorchMode) {
+        assertIsOnSessionQueue()
+
+        guard let captureDevice = videoCaptureDevice, captureDevice.hasTorch, captureDevice.isTorchModeSupported(mode) else { return }
+        do {
+            try captureDevice.lockForConfiguration()
+            captureDevice.torchMode = mode
+            captureDevice.unlockForConfiguration()
+        } catch {
+            owsFailDebug("Error setting torchMode: \(error)")
+        }
+    }
+
+    // MARK: - Audio Recording Stack
+
+    private let recordingAudioActivity = AudioActivity(audioDescription: "VideoCapture", behavior: .playAndRecord)
+
+    private func startAudioCapture() -> Bool {
+        assertIsOnSessionQueue()
+
+        // This check will fail if we do not have recording permissions.
+        guard audioSession.startAudioActivity(recordingAudioActivity) else {
+            Logger.warn("Unable to start recording audio activity!")
+            return false
+        }
+
+        guard let audioDevice = AVCaptureDevice.default(for: .audio) else {
+            Logger.warn("Missing audio capture device!")
+            return false
+        }
+
+        // NOTE: No need to call `beginConfiguration`/`commitConfiguration` when adding input.
+        do {
+            let audioDeviceInput = try AVCaptureDeviceInput(device: audioDevice)
+            guard audioCaptureSession.canAddInput(audioDeviceInput) else {
+                owsFailBeta("Could not add audio device input to the session")
+                return false
+            }
+            audioCaptureSession.addInput(audioDeviceInput)
+            self.audioCaptureInput = audioDeviceInput
+        } catch let error {
+            Logger.warn("Failed to create audioDeviceInput: \(error)")
+            return false
+        }
+
+        return true
+    }
+
+    private func stopAudioCapture() {
+        assertIsOnSessionQueue()
+
+        guard let audioCaptureInput else {
+            Logger.warn("audioCaptureInput was nil - recording permissions may have been disabled?")
+            return
+        }
+
+        // NOTE: No need to call `beginConfiguration`/`commitConfiguration` when removing an input.
+        audioCaptureSession.removeInput(audioCaptureInput)
+        self.audioCaptureInput = nil
+
+        audioSession.endAudioActivity(recordingAudioActivity)
+    }
+}
+
+// MARK: -
+extension CameraCaptureSession: VideoCaptureDelegate {
+
+    fileprivate func videoCaptureDidStartRecording(_ videoCapture: VideoCapture) {
         AssertIsOnMainThread()
+        delegate?.cameraCaptureSessionDidStartVideoRecording(self)
+    }
 
-        videoRecordingState = .stopping
+    fileprivate func videoCaptureWillStopRecording(_ videoCapture: VideoCapture) {
+        AssertIsOnMainThread()
+        // Proper state might not be set if recording is stopped not by user.
+        if videoRecordingState == .started {
+            videoRecordingState = .stopping
+        }
+    }
 
-        firstly(on: captureOutput.movieRecordingQueue) {
-            self.captureOutput.cancelVideo(delegate: self)
-        }.done(on: DispatchQueue.main) {
-            AssertIsOnMainThread()
+    fileprivate func videoCapture(_ videoCapture: VideoCapture, didUpdateRecordingDuration duration: TimeInterval) {
+        AssertIsOnMainThread()
+        delegate?.cameraCaptureSession(self, videoRecordingDurationChanged: duration)
+    }
+
+    fileprivate func videoCapture(_ videoCapture: VideoCapture, didFinishWith result: Result<URL, Error>) {
+        AssertIsOnMainThread()
+        Logger.verbose("Video recording ended with result: \(result)")
 
-            self.sessionQueue.async {
-                self.setTorchMode(.off)
-                self.stopAudioCapture()
+        switch result {
+        case .success(let outputURL):
+            if videoRecordingState != .canceling {
+                handleVideoRecording(at: outputURL)
             }
 
-            self.videoRecordingState = .stopped
-            self.delegate?.photoCaptureDidCancelRecording(self)
-        }.catch { error in
-            self.handleMovieCaptureError(error)
-        }
-    }
+        case .failure(let error):
+            handleVideoCaptureError(error)
+        }
+
+        sessionQueue.async {
+            self.cleanUpAfterVideoRecording()
+        }
+    }
+}
+
+// MARK: -
+
+extension CameraCaptureSession: PhotoCaptureDelegate {
+
+    fileprivate func photoCaptureDidProduce(result: Result<Data, Error>) {
+        Logger.verbose("")
+        AssertIsOnMainThread()
+        guard let delegate = delegate else { return }
 
-    private func setTorchMode(_ mode: AVCaptureDevice.TorchMode) {
-        assertIsOnSessionQueue()
+        switch result {
+        case .failure(let error):
+            delegate.cameraCaptureSession(self, didFailWith: error)
+        case .success(let photoData):
+            let dataSource = DataSourceValue.dataSource(with: photoData, utiType: kUTTypeJPEG as String)
 
-        guard let captureDevice = captureDevice, captureDevice.hasTorch, captureDevice.isTorchModeSupported(mode) else { return }
-        do {
-            try captureDevice.lockForConfiguration()
-            captureDevice.torchMode = mode
-            captureDevice.unlockForConfiguration()
-        } catch {
-            owsFailDebug("Error setting torchMode: \(error)")
+            let attachment = SignalAttachment.attachment(dataSource: dataSource, dataUTI: kUTTypeJPEG as String)
+            delegate.cameraCaptureSession(self, didFinishProcessing: attachment)
         }
     }
 }
@@ -898,18 +1002,15 @@ class PhotoCapture: NSObject {
 
 class CapturePreviewView: UIView {
 
-    let previewLayer: AVCaptureVideoPreviewLayer
-
-    override var bounds: CGRect {
-        didSet {
-            previewLayer.frame = bounds
-        }
+    override class var layerClass: AnyClass {
+        return AVCaptureVideoPreviewLayer.self
     }
 
-    override var frame: CGRect {
-        didSet {
-            previewLayer.frame = bounds
+    var previewLayer: AVCaptureVideoPreviewLayer {
+        guard let layer = layer as? AVCaptureVideoPreviewLayer else {
+            fatalError("Expected `AVCaptureVideoPreviewLayer` type for layer. Check PreviewView.layerClass implementation.")
         }
+        return layer
     }
 
     override var contentMode: UIView.ContentMode {
@@ -941,15 +1042,13 @@ class CapturePreviewView: UIView {
     }
 
     init(session: AVCaptureSession) {
-        previewLayer = AVCaptureVideoPreviewLayer(session: session)
+        super.init(frame: .zero)
+        previewLayer.session = session
         if Platform.isSimulator {
             // helpful for debugging layout on simulator which has no real capture device
             previewLayer.backgroundColor = UIColor.green.withAlphaComponent(0.4).cgColor
         }
-        super.init(frame: .zero)
-        self.contentMode = .scaleAspectFill
-        previewLayer.frame = bounds
-        layer.addSublayer(previewLayer)
+        contentMode = .scaleAspectFill
     }
 
     @available(*, unavailable, message: "Use init(session:) instead")
@@ -960,7 +1059,7 @@ class CapturePreviewView: UIView {
 
 // MARK: -
 
-extension PhotoCapture: VolumeButtonObserver {
+extension CameraCaptureSession: VolumeButtonObserver {
 
     func didPressVolumeButton(with identifier: VolumeButtons.Identifier) {
         delegate?.beginCaptureButtonAnimation(0.5)
@@ -975,43 +1074,43 @@ extension PhotoCapture: VolumeButtonObserver {
     }
 
     func didBeginLongPressVolumeButton(with identifier: VolumeButtons.Identifier) {
-        beginMovieCapture()
+        startVideoRecording()
     }
 
     func didCompleteLongPressVolumeButton(with identifier: VolumeButtons.Identifier) {
-        completeMovieCapture()
+        stopVideoRecording()
     }
 
     func didCancelLongPressVolumeButton(with identifier: VolumeButtons.Identifier) {
-        cancelMovieCapture()
+        cancelVideoRecording()
     }
 }
 
 // MARK: -
 
-extension PhotoCapture: CameraCaptureControlDelegate {
+extension CameraCaptureSession: CameraCaptureControlDelegate {
 
     func cameraCaptureControlDidRequestCapturePhoto(_ control: CameraCaptureControl) {
         takePhoto()
     }
 
     func cameraCaptureControlDidRequestStartVideoRecording(_ control: CameraCaptureControl) {
-        if let captureDevice = captureDevice {
-            self.initialSlideZoomFactor = captureDevice.videoZoomFactor
+        if let videoCaptureDevice {
+            initialSlideZoomFactor = videoCaptureDevice.videoZoomFactor
         }
-        beginMovieCapture()
+        startVideoRecording()
     }
 
     func cameraCaptureControlDidRequestFinishVideoRecording(_ control: CameraCaptureControl) {
-        completeMovieCapture()
+        stopVideoRecording()
     }
 
     func cameraCaptureControlDidRequestCancelVideoRecording(_ control: CameraCaptureControl) {
-        cancelMovieCapture()
+        cancelVideoRecording()
     }
 
     func didPressStopCaptureButton(_ control: CameraCaptureControl) {
-        completeMovieCapture()
+        stopVideoRecording()
     }
 
     var zoomScaleReferenceDistance: CGFloat? {
@@ -1026,552 +1125,341 @@ extension PhotoCapture: CameraCaptureControlDelegate {
 
 // MARK: -
 
-extension PhotoCapture: CaptureOutputDelegate {
-
-    var captureOutputAspectRatio: CGFloat {
-        AssertIsOnMainThread()
-        let size = UIScreen.main.bounds.size
-        let screenAspect: CGFloat
-        if size.width == 0 || size.height == 0 {
-            screenAspect = 0
-        } else if size.width > size.height {
-            screenAspect = size.height / size.width
-        } else {
-            screenAspect = size.width / size.height
-        }
-        return screenAspect.clamp(9/16, 3/4)
-    }
-
-    var captureOutputPhotoRect: CGRect {
-        AssertIsOnMainThread()
-        return previewView.previewLayer.metadataOutputRectConverted(fromLayerRect: previewView.previewLayer.bounds)
-    }
-
-    // MARK: - Photo
-
-    func captureOutputDidCapture(photoData: Swift.Result<Data, Error>) {
-        Logger.verbose("")
-        AssertIsOnMainThread()
-        guard let delegate = delegate else { return }
-
-        switch photoData {
-        case .failure(let error):
-            delegate.photoCapture(self, didFailProcessing: error)
-        case .success(let photoData):
-            let dataSource = DataSourceValue.dataSource(with: photoData, utiType: kUTTypeJPEG as String)
-
-            let attachment = SignalAttachment.attachment(dataSource: dataSource, dataUTI: kUTTypeJPEG as String)
-            delegate.photoCapture(self, didFinishProcessing: attachment)
-        }
-    }
-
-    // MARK: - Movie
-
-    func captureOutputDidCapture(movieUrl: Swift.Result<URL, Error>) {
-        Logger.verbose("")
-        AssertIsOnMainThread()
-        guard let delegate = delegate else { return }
-
-        switch movieUrl {
-        case .failure(let error):
-            self.handleMovieCaptureError(error)
-        case .success(let movieUrl):
-            guard OWSMediaUtils.isValidVideo(path: movieUrl.path) else {
-                self.handleMovieCaptureError(PhotoCaptureError.invalidVideo)
-                return
-            }
-            guard let dataSource = try? DataSourcePath.dataSource(with: movieUrl, shouldDeleteOnDeallocation: true) else {
-                self.handleMovieCaptureError(PhotoCaptureError.captureFailed)
-                return
-            }
-            let attachment = SignalAttachment.attachment(dataSource: dataSource, dataUTI: kUTTypeMPEG4 as String)
-
-            BenchEventComplete(eventId: "Movie Processing")
-            delegate.photoCapture(self, didFinishProcessing: attachment)
-        }
-    }
-
-    /// The AVCaptureFileOutput can return an error even though recording succeeds.
-    /// I can't find useful documentation on this, but Apple's example AVCam app silently
-    /// discards these errors, so we do the same.
-    /// These spurious errors can be reproduced 1/3 of the time when making a series of short videos.
-    private func didSucceedDespiteError(_ error: Error) -> Bool {
-        let nsError = error as NSError
-        guard let successfullyFinished = nsError.userInfo[AVErrorRecordingSuccessfullyFinishedKey] as? Bool else {
-            return false
-        }
-
-        return successfullyFinished
-    }
-}
-
-// MARK: - Capture Adapter
-
-protocol CaptureOutputDelegate: AnyObject {
-    var session: AVCaptureSession { get }
-    func assertIsOnSessionQueue()
-    func stopCapture() -> Guarantee<Void>
-    func captureOutputDidCapture(photoData: Swift.Result<Data, Error>)
-    func captureOutputDidCapture(movieUrl: Swift.Result<URL, Error>)
-    var captureOrientation: AVCaptureVideoOrientation { get }
-    var captureOutputAspectRatio: CGFloat { get }
-    var captureOutputPhotoRect: CGRect { get }
-}
-
-// MARK: -
+private protocol VideoCaptureDelegate: AnyObject {
 
-protocol ImageCaptureOutput: AnyObject {
-    func availableDeviceTypes(forPosition position: AVCaptureDevice.Position) -> [AVCaptureDevice.DeviceType]
-    func cameraSwitchOverZoomFactors(forPosition position: AVCaptureDevice.Position) -> [CGFloat]
-    var avOutput: AVCaptureOutput { get }
-    var flashMode: AVCaptureDevice.FlashMode { get set }
-    func videoDevice(for deviceType: AVCaptureDevice.DeviceType, position: AVCaptureDevice.Position) -> AVCaptureDevice?
-    func takePhoto(delegate: CaptureOutputDelegate, captureRect: CGRect)
+    func videoCaptureDidStartRecording(_ videoCapture: VideoCapture)
+    func videoCaptureWillStopRecording(_ videoCapture: VideoCapture)
+    func videoCapture(_ videoCapture: VideoCapture, didUpdateRecordingDuration duration: TimeInterval)
+    func videoCapture(_ videoCapture: VideoCapture, didFinishWith result: Result<URL, Error>)
 }
 
-// MARK: -
-
-class CaptureOutput: NSObject {
+private class VideoCapture: NSObject, AVCaptureVideoDataOutputSampleBufferDelegate, AVCaptureAudioDataOutputSampleBufferDelegate {
 
-    let session: AVCaptureSession
-    let imageOutput: ImageCaptureOutput
+    let videoDataOutput = AVCaptureVideoDataOutput()
+    let audioDataOutput = AVCaptureAudioDataOutput()
 
-    let videoDataOutput: AVCaptureVideoDataOutput
-    let audioDataOutput: AVCaptureAudioDataOutput
+    private static let videoCaptureQueue = DispatchQueue(label: "VideoCapture.video", qos: .userInteractive)
+    private var videoCaptureQueue: DispatchQueue { VideoCapture.videoCaptureQueue }
 
-    static let movieRecordingQueue = DispatchQueue(label: "CaptureOutput.movieRecordingQueue", qos: .userInitiated)
-    var movieRecordingQueue: DispatchQueue { CaptureOutput.movieRecordingQueue }
-
-    // A user might cancel movie recording before recording has
-    // begun (e.g. an instance of MovieRecording has been created),
-    // with a very short long press gesture.
-    // We handle that case by marking that recording as aborted
-    // before it exists using this box.
-    struct MovieRecordingBox {
-
-        private let invalidated = AtomicBool(false)
-        private let movieRecording = AtomicOptional<MovieRecording>(nil)
-
-        func set(_ value: MovieRecording) {
-            movieRecording.set(value)
-        }
+    private static let audioCaptureQueue = DispatchQueue(label: "VideoCapture.audio", qos: .userInteractive)
+    private var audioCaptureQueue: DispatchQueue { VideoCapture.audioCaptureQueue }
 
-        @discardableResult
-        func invalidate() -> MovieRecording? {
-            let value = self.value
-            invalidated.set(true)
-            return value
-        }
+    private let recordingQueue = DispatchQueue(label: "VideoCapture.recording", qos: .userInteractive)
 
-        var value: MovieRecording? {
-            guard !invalidated.get() else {
-                return nil
-            }
-            return movieRecording.get()
-        }
-    }
-    private let _movieRecordingBox = AtomicOptional<MovieRecordingBox>(nil)
-    var currentMovieRecording: MovieRecording? {
-        _movieRecordingBox.get()?.value
-    }
-    @discardableResult
-    func clearMovieRecording() -> MovieRecording? {
-        let box = _movieRecordingBox.swap(nil)
-        return box?.invalidate()
-    }
-    func newMovieRecordingBox() -> MovieRecordingBox {
-        let newBox = MovieRecordingBox()
-        let oldBox = _movieRecordingBox.swap(newBox)
-        oldBox?.invalidate()
-        return newBox
-    }
+    private var assetWriter: AVAssetWriter?
+    private var videoWriterInput: AVAssetWriterInput?
+    private var audioWriterInput: AVAssetWriterInput?
 
-    // MARK: - Init
+    private var isAssetWriterSessionStarted = false
+    private var isAssetWriterAcceptingSampleBuffers = AtomicBool(false)
+    private var needsFinishAssetWriterSession = false
 
-    init(session: AVCaptureSession) {
-        imageOutput = PhotoCaptureOutputAdaptee()
+    weak var delegate: VideoCaptureDelegate?
 
-        videoDataOutput = AVCaptureVideoDataOutput()
-        videoDataOutput.alwaysDiscardsLateVideoFrames = false
-        audioDataOutput = AVCaptureAudioDataOutput()
+    private let videoSampleTimeLock = UnfairLock()
+    private var timeOfFirstAppendedVideoSampleBuffer = CMTime.invalid
+    private var timeOfLastAppendedVideoSampleBuffer = CMTime.invalid
 
-        self.session = session
+    override init() {
         super.init()
 
-        videoDataOutput.setSampleBufferDelegate(self, queue: movieRecordingQueue)
-        audioDataOutput.setSampleBufferDelegate(self, queue: movieRecordingQueue)
-    }
-
-    var photoOutput: AVCaptureOutput? {
-        return imageOutput.avOutput
-    }
-
-    var flashMode: AVCaptureDevice.FlashMode {
-        get { return imageOutput.flashMode }
-        set { imageOutput.flashMode = newValue }
-    }
-
-    func videoDevice(for deviceType: AVCaptureDevice.DeviceType, position: AVCaptureDevice.Position) -> AVCaptureDevice? {
-        return imageOutput.videoDevice(for: deviceType, position: position)
-    }
-
-    func takePhoto(delegate: CaptureOutputDelegate, captureRect: CGRect) {
-        delegate.assertIsOnSessionQueue()
-
-        guard let photoOutput = photoOutput else {
-            owsFailDebug("photoOutput was unexpectedly nil")
-            return
-        }
-
-        guard let photoVideoConnection = photoOutput.connection(with: .video) else {
-            owsFailDebug("photoVideoConnection was unexpectedly nil")
-            return
-        }
-
-        ImpactHapticFeedback.impactOccured(style: .medium)
-
-        let videoOrientation = delegate.captureOrientation
-        photoVideoConnection.videoOrientation = videoOrientation
-        Logger.verbose("videoOrientation: \(videoOrientation), deviceOrientation: \(UIDevice.current.orientation)")
-
-        return imageOutput.takePhoto(delegate: delegate, captureRect: captureRect)
+        videoDataOutput.alwaysDiscardsLateVideoFrames = false
+        videoDataOutput.setSampleBufferDelegate(self, queue: videoCaptureQueue)
+        audioDataOutput.setSampleBufferDelegate(self, queue: audioCaptureQueue)
     }
 
-    // MARK: - Movie Output
-
-    func beginMovie(
-        delegate: CaptureOutputDelegate,
+    func beginRecording(
+        captureOrientation: AVCaptureVideoOrientation,
         aspectRatio: CGFloat,
         includeAudio: Bool
-    ) throws -> MovieRecording {
+    ) throws {
         Logger.verbose("")
 
-        delegate.assertIsOnSessionQueue()
-
         guard let videoConnection = videoDataOutput.connection(with: .video) else {
             throw OWSAssertionError("videoConnection was unexpectedly nil")
         }
-        let videoOrientation = delegate.captureOrientation
-        videoConnection.videoOrientation = videoOrientation
+        videoConnection.videoOrientation = captureOrientation
 
-        owsAssertDebug(currentMovieRecording == nil)
         let outputURL = OWSFileSystem.temporaryFileUrl(fileExtension: "mp4")
         let assetWriter = try AVAssetWriter(outputURL: outputURL, fileType: .mp4)
 
-        guard let recommendedSettings = self.videoDataOutput.recommendedVideoSettingsForAssetWriter(writingTo: .mp4) else {
+        guard var videoSettings = videoDataOutput.recommendedVideoSettings(
+            forVideoCodecType: .h264,
+            assetWriterOutputFileType: .mp4
+        ) else {
             throw OWSAssertionError("videoSettings was unexpectedly nil")
         }
-        guard let capturedWidth: CGFloat = recommendedSettings[AVVideoWidthKey] as? CGFloat else {
-            throw OWSAssertionError("capturedWidth was unexpectedly nil")
-        }
-        guard let capturedHeight: CGFloat = recommendedSettings[AVVideoHeightKey] as? CGFloat else {
-            throw OWSAssertionError("capturedHeight was unexpectedly nil")
+        guard
+            let capturedWidth: CGFloat = videoSettings[AVVideoWidthKey] as? CGFloat,
+            let capturedHeight: CGFloat = videoSettings[AVVideoHeightKey] as? CGFloat
+        else {
+            throw OWSAssertionError("video dimensions were unexpectedly nil")
         }
         let capturedSize = CGSize(width: capturedWidth, height: capturedHeight)
-
-        // video specs from Signal-Android: 2Mbps video 192K audio, 720P 30 FPS
-        let maxDimension: CGFloat = 1280 // 720p
-
         let aspectSize = capturedSize.cropped(toAspectRatio: aspectRatio)
-        let outputSize = aspectSize.scaledToFit(max: maxDimension)
+        let outputSize = aspectSize.scaledToFit(max: 1280) // 720p
 
-        // See AVVideoSettings.h
-        let videoSettings: [String: Any] = [
+        // video specs from Signal-Android: 2Mbps video 192K audio, 720P 30 FPS
+        let customSettings: [String: Any] = [
             AVVideoWidthKey: outputSize.width,
             AVVideoHeightKey: outputSize.height,
             AVVideoScalingModeKey: AVVideoScalingModeResizeAspectFill,
-            AVVideoCodecKey: AVVideoCodecType.h264,
             AVVideoCompressionPropertiesKey: [
                 AVVideoAverageBitRateKey: 2000000,
                 AVVideoProfileLevelKey: AVVideoProfileLevelH264Baseline41,
                 AVVideoMaxKeyFrameIntervalKey: 90
             ]
         ]
+        videoSettings.merge(customSettings) { $1 }
+
+        guard assetWriter.canApply(outputSettings: videoSettings, forMediaType: .video) else {
+            throw PhotoCaptureError.initializationFailed
+        }
 
-        Logger.info("videoOrientation: \(videoOrientation), captured: \(capturedWidth)x\(capturedHeight), output: \(outputSize.width)x\(outputSize.height), aspectRatio: \(aspectRatio)")
+        Logger.info("videoOrientation: \(captureOrientation), captured: \(capturedWidth)x\(capturedHeight), output: \(outputSize.width)x\(outputSize.height), aspectRatio: \(aspectRatio)")
 
-        let videoInput = AVAssetWriterInput(mediaType: .video, outputSettings: videoSettings)
-        videoInput.expectsMediaDataInRealTime = true
-        assetWriter.add(videoInput)
+        let videoWriterInput = AVAssetWriterInput(
+            mediaType: .video,
+            outputSettings: videoSettings,
+            sourceFormatHint: nil
+        )
+        videoWriterInput.expectsMediaDataInRealTime = true
+        guard assetWriter.canAdd(videoWriterInput) else {
+            throw PhotoCaptureError.initializationFailed
+        }
+        assetWriter.add(videoWriterInput)
+        self.videoWriterInput = videoWriterInput
 
-        var audioInput: AVAssetWriterInput?
         if includeAudio {
-            if let audioSettings = self.audioDataOutput.recommendedAudioSettingsForAssetWriter(writingTo: .mp4) {
-                audioInput = AVAssetWriterInput(mediaType: .audio, outputSettings: audioSettings)
-                audioInput!.expectsMediaDataInRealTime = true
-                assetWriter.add(audioInput!)
-            } else {
-                owsFailDebug("audioSettings was unexpectedly nil!")
+            guard
+                let audioSettings = audioDataOutput.recommendedAudioSettingsForAssetWriter(writingTo: .mp4),
+                assetWriter.canApply(outputSettings: audioSettings, forMediaType: .audio)
+            else {
+                throw PhotoCaptureError.initializationFailed
             }
+            let audioWriterInput = AVAssetWriterInput(mediaType: .audio, outputSettings: audioSettings)
+            audioWriterInput.expectsMediaDataInRealTime = true
+            guard assetWriter.canAdd(audioWriterInput) else {
+                throw PhotoCaptureError.initializationFailed
+            }
+            assetWriter.add(audioWriterInput)
+            self.audioWriterInput = audioWriterInput
         } else {
             Logger.info("Not including audio.")
         }
 
-        return MovieRecording(assetWriter: assetWriter, videoInput: videoInput, audioInput: audioInput)
+        guard assetWriter.startWriting() else {
+            throw PhotoCaptureError.initializationFailed
+        }
+        self.assetWriter = assetWriter
+
+        isAssetWriterAcceptingSampleBuffers.set(true)
     }
 
-    func completeMovie(delegate: CaptureOutputDelegate) {
+    func stopRecording() {
         Logger.verbose("")
+        AssertIsOnMainThread()
 
-        assertOnQueue(movieRecordingQueue)
-
-        firstly {
-            delegate.stopCapture()
-        }.then(on: CaptureOutput.movieRecordingQueue) { [weak self] _ -> Promise<URL> in
-            assertOnQueue(CaptureOutput.movieRecordingQueue)
-            guard let movieRecording = self?.clearMovieRecording() else {
-                // If the user cancels a video before recording begins,
-                // the instance of MovieRecording might not be set yet.
-                // clearMovieRecording() will ensure that race does not
-                // cause problems.
-                Logger.warn("Movie recording is nil.")
-                throw PhotoCaptureError.invalidVideo
-            }
-            return movieRecording.finish()
-        }.done { outputUrl in
-            delegate.captureOutputDidCapture(movieUrl: .success(outputUrl))
-        }.catch { error in
-            delegate.captureOutputDidCapture(movieUrl: .failure(error))
+        // Make video recording at least 1 second long.
+        let duration = durationOfCurrentRecording
+        let recordedDurationSeconds: TimeInterval = duration.isValid ? duration.seconds : 0
+        let timeExtension: TimeInterval = max(0, 1 - recordedDurationSeconds)
+        recordingQueue.asyncAfter(deadline: .now() + timeExtension) {
+            self.needsFinishAssetWriterSession = true
         }
     }
 
-    func cancelVideo(delegate: CaptureOutputDelegate) {
-        assertOnQueue(movieRecordingQueue)
+    var durationOfCurrentRecording: CMTime {
+        videoSampleTimeLock.lock()
+        let timeOfFirstAppendedVideoSampleBuffer = timeOfFirstAppendedVideoSampleBuffer
+        let timeOfLastAppendedVideoSampleBuffer = timeOfLastAppendedVideoSampleBuffer
+        videoSampleTimeLock.unlock()
 
-        self.clearMovieRecording()
+        guard timeOfFirstAppendedVideoSampleBuffer.isValid, timeOfLastAppendedVideoSampleBuffer.isValid else {
+            return .zero
+        }
+        return CMTimeSubtract(timeOfLastAppendedVideoSampleBuffer, timeOfFirstAppendedVideoSampleBuffer)
     }
-}
-
-// MARK: -
 
-class MovieRecording {
+    private func finishAssetWriterSession() {
+        guard let assetWriter else {
+            owsFailBeta("assetWriter is nil")
+            return
+        }
 
-    let assetWriter: AVAssetWriter
-    let videoInput: AVAssetWriterInput
-    let audioInput: AVAssetWriterInput?
+        isAssetWriterAcceptingSampleBuffers.set(false)
 
-    enum State {
-        case unstarted, recording, finished
-    }
-    private(set) var state: State = .unstarted
+        videoSampleTimeLock.lock()
+        let timeOfLastAppendedVideoSampleBuffer = timeOfLastAppendedVideoSampleBuffer
+        videoSampleTimeLock.unlock()
 
-    init(assetWriter: AVAssetWriter, videoInput: AVAssetWriterInput, audioInput: AVAssetWriterInput?) {
-        self.assetWriter = assetWriter
-        self.videoInput = videoInput
-        self.audioInput = audioInput
-    }
+        // Prevent assetWriter.startSession() from being called if for some reason it wasn't called yet.
+        isAssetWriterSessionStarted = true
 
-    func start(sampleBuffer: CMSampleBuffer) throws {
-        Logger.verbose("")
-        switch state {
-        case .unstarted:
-            state = .recording
-            guard assetWriter.startWriting() else {
-                throw OWSAssertionError("startWriting() was unexpectedly false")
-            }
-            assetWriter.startSession(atSourceTime: CMSampleBufferGetPresentationTimeStamp(sampleBuffer))
-        default:
-            throw OWSAssertionError("unexpected state: \(state)")
+        if timeOfLastAppendedVideoSampleBuffer.isValid {
+            assetWriter.endSession(atSourceTime: timeOfLastAppendedVideoSampleBuffer)
+        } else {
+            owsFailDebug("No timeOfLastAppendedVideoSampleBuffer")
         }
-    }
 
-    func finish() -> Promise<URL> {
-        assertOnQueue(CaptureOutput.movieRecordingQueue)
-
-        Logger.verbose("")
-        switch state {
-        case .recording:
-            state = .finished
-            audioInput?.markAsFinished()
-            videoInput.markAsFinished()
-            return Promise<URL> { future -> Void in
-                let assetWriter = self.assetWriter
-                assetWriter.finishWriting {
-                    if assetWriter.status == .completed,
-                       assetWriter.error == nil {
-                        future.resolve(self.assetWriter.outputURL)
-                    } else {
-                        // If the user cancels a video right after recording
-                        // begins, recording is expected to fail.
-                        future.reject(PhotoCaptureError.invalidVideo)
-                    }
+        assetWriter.finishWriting {
+            self.recordingQueue.async {
+                let result: Result<URL, Error>
+                if assetWriter.status == .completed && assetWriter.error == nil {
+                    result = .success(assetWriter.outputURL)
+                } else {
+                    result = .failure(PhotoCaptureError.invalidVideo)
+                }
+                DispatchQueue.main.async {
+                    self.delegate?.videoCapture(self, didFinishWith: result)
                 }
+
+                self.cleanUp()
             }
-        default:
-            Logger.warn("Unexpected state: \(state)")
-            return Promise(error: PhotoCaptureError.invalidVideo)
         }
     }
-}
 
-// MARK: -
+    private func append(sampleBuffer: CMSampleBuffer, to assetWriterInput: AVAssetWriterInput) {
+        guard let assetWriter else {
+            owsFailBeta("assetWriter is nil")
+            return
+        }
 
-extension CaptureOutput: AVCaptureVideoDataOutputSampleBufferDelegate, AVCaptureAudioDataOutputSampleBufferDelegate {
+        let presentationTime = CMSampleBufferGetPresentationTimeStamp(sampleBuffer)
 
-    func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
-        assertOnQueue(movieRecordingQueue)
+        if !isAssetWriterSessionStarted && assetWriterInput == videoWriterInput {
+            assetWriter.startSession(atSourceTime: presentationTime)
+            isAssetWriterSessionStarted = true
+            DispatchQueue.main.async {
+                self.delegate?.videoCaptureDidStartRecording(self)
+            }
+        }
 
-        guard let movieRecording = currentMovieRecording else {
-            // `movieRecording` is assigned async after the capture pipeline has been set up.
-            // We'll drop a few frames before we're ready to start recording.
+        let acceptingSampleBuffers = isAssetWriterAcceptingSampleBuffers.get()
+        guard acceptingSampleBuffers && isAssetWriterSessionStarted else {
+            Logger.verbose("Not accepting sample buffers at the moment.")
+            return
+        }
+        guard assetWriterInput.isReadyForMoreMediaData else {
+            Logger.verbose("Input not ready for more media data")
             return
         }
 
-        do {
-            if movieRecording.state == .unstarted {
-                try movieRecording.start(sampleBuffer: sampleBuffer)
-            }
+        guard assetWriterInput.append(sampleBuffer) else {
+            Logger.error("Input failed to append sample buffer.")
+            needsFinishAssetWriterSession = true
+            return
+        }
 
-            guard movieRecording.state == .recording else {
-                owsAssertDebug(movieRecording.state == .finished)
-                Logger.verbose("ignoring samples since recording has finished.")
-                return
+        if assetWriterInput == videoWriterInput {
+            videoSampleTimeLock.lock()
+            timeOfLastAppendedVideoSampleBuffer = presentationTime
+            if !timeOfFirstAppendedVideoSampleBuffer.isValid {
+                timeOfFirstAppendedVideoSampleBuffer = presentationTime
             }
+            videoSampleTimeLock.unlock()
 
-            if output == self.videoDataOutput {
-                movieRecordingQueue.async {
-                    if movieRecording.videoInput.isReadyForMoreMediaData {
-                        movieRecording.videoInput.append(sampleBuffer)
-                    } else {
-                        Logger.verbose("videoInput was not ready for more data")
-                    }
-                }
-            } else if output == self.audioDataOutput {
-                movieRecordingQueue.async {
-                    if
-                        let audioInput = movieRecording.audioInput,
-                        audioInput.isReadyForMoreMediaData
-                    {
-                        audioInput.append(sampleBuffer)
-                    } else {
-                        Logger.verbose("audioInput was not present or ready for more data")
-                    }
-                }
-            } else {
-                owsFailDebug("unknown output: \(output)")
+            let recordingDuration = self.durationOfCurrentRecording.seconds
+            DispatchQueue.main.async {
+                self.delegate?.videoCapture(self, didUpdateRecordingDuration: recordingDuration)
             }
-        } catch {
-            owsFailDebug("error: \(error)")
         }
-    }
 
-    func captureOutput(_ output: AVCaptureOutput, didDrop sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
-        Logger.error("dropped sampleBuffer from connection: \(connection)")
+        if needsFinishAssetWriterSession {
+            DispatchQueue.main.async {
+                self.delegate?.videoCaptureWillStopRecording(self)
+            }
+            finishAssetWriterSession()
+            needsFinishAssetWriterSession = false
+            return
+        }
     }
-}
 
-// MARK: -
+    func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
+        guard isAssetWriterAcceptingSampleBuffers.get() else {
+            return
+        }
 
-class PhotoCaptureOutputAdaptee: NSObject, ImageCaptureOutput {
+        guard let formatDescription = CMSampleBufferGetFormatDescription(sampleBuffer) else {
+            owsFailDebug("Failed to get format description")
+            return
+        }
+        let mediaType = CMFormatDescriptionGetMediaType(formatDescription)
 
-    let photoOutput = AVCapturePhotoOutput()
-    var avOutput: AVCaptureOutput {
-        return photoOutput
+        recordingQueue.async {
+            if mediaType == kCMMediaType_Video, let videoWriterInput = self.videoWriterInput {
+                self.append(sampleBuffer: sampleBuffer, to: videoWriterInput)
+            } else if mediaType == kCMMediaType_Audio, let audioWriterInput = self.audioWriterInput {
+                self.append(sampleBuffer: sampleBuffer, to: audioWriterInput)
+            } else {
+                owsFailDebug("Unknown output for media type [\(mediaType)]")
+                self.needsFinishAssetWriterSession = true
+            }
+        }
     }
 
-    private lazy var availableRearDeviceMap: [AVCaptureDevice.DeviceType: AVCaptureDevice] = {
-        return availableDevices(forPosition: .back)
-    }()
-
-    private lazy var availableFrontDeviceMap: [AVCaptureDevice.DeviceType: AVCaptureDevice] = {
-        return availableDevices(forPosition: .front)
-    }()
-
-    func availableDeviceTypes(forPosition position: AVCaptureDevice.Position) -> [AVCaptureDevice.DeviceType] {
-        switch position {
-        case .front, .unspecified:
-            return Array(availableFrontDeviceMap.keys)
+    private func cleanUp() {
+        assetWriter = nil
+        videoWriterInput = nil
+        audioWriterInput = nil
+        isAssetWriterSessionStarted = false
+        videoSampleTimeLock.lock()
+        timeOfFirstAppendedVideoSampleBuffer = .invalid
+        timeOfLastAppendedVideoSampleBuffer = .invalid
+        videoSampleTimeLock.unlock()
+    }
+}
 
-        case .back:
-            return Array(availableRearDeviceMap.keys)
+// MARK: -
 
-        @unknown default:
-            owsFailDebug("Unknown AVCaptureDevice.Position: [\(position)]")
-            return []
-        }
-    }
+private protocol PhotoCaptureDelegate: AnyObject {
 
-    func cameraSwitchOverZoomFactors(forPosition position: AVCaptureDevice.Position) -> [CGFloat] {
-        let deviceMap = position == .front ? availableFrontDeviceMap : availableRearDeviceMap
+    func photoCaptureDidProduce(result: Result<Data, Error>)
+}
 
-        guard #available(iOS 13, *) else {
-            // No iOS 12 device can have triple camera system.
-            if deviceMap[.builtInDualCamera] != nil {
-                return UIDevice.current.isPlusSizePhone ? [ 2.5 ] : [ 2 ]
-            }
-            return []
-        }
+private class PhotoCapture: NSObject {
 
-        if let multiCameraDevice = deviceMap[.builtInTripleCamera] ?? deviceMap[.builtInDualWideCamera] ?? deviceMap[.builtInDualCamera] {
-            return multiCameraDevice.virtualDeviceSwitchOverVideoZoomFactors.map { CGFloat(truncating: $0) }
-        }
-        return []
-    }
+    let avCaptureOutput = AVCapturePhotoOutput()
 
     var flashMode: AVCaptureDevice.FlashMode = .off
 
     override init() {
-        photoOutput.isLivePhotoCaptureEnabled = false
-        photoOutput.isHighResolutionCaptureEnabled = true
+        super.init()
+
+        avCaptureOutput.isLivePhotoCaptureEnabled = false
+        avCaptureOutput.isHighResolutionCaptureEnabled = true
     }
 
     private var photoProcessors: [Int64: PhotoProcessor] = [:]
 
-    func takePhoto(delegate: CaptureOutputDelegate, captureRect: CGRect) {
-        delegate.assertIsOnSessionQueue()
-
-        let settings = buildCaptureSettings()
-
-        let photoProcessor = PhotoProcessor(delegate: delegate, captureRect: captureRect, completion: { [weak self] in
-            self?.photoProcessors[settings.uniqueID] = nil
-        })
-        photoProcessors[settings.uniqueID] = photoProcessor
-        photoOutput.capturePhoto(with: settings, delegate: photoProcessor)
-    }
-
-    func videoDevice(for deviceType: AVCaptureDevice.DeviceType, position: AVCaptureDevice.Position) -> AVCaptureDevice? {
-        switch position {
-        case .back:
-            return availableRearDeviceMap[deviceType]
-        case .front:
-            return availableFrontDeviceMap[deviceType]
-        default:
-            owsFailDebug("Requested invalid camera position")
-            return nil
+    func takePhoto(delegate: PhotoCaptureDelegate, captureOrientation: AVCaptureVideoOrientation, captureRect: CGRect) {
+        guard let avCaptureConnection = avCaptureOutput.connection(with: .video) else {
+            owsFailBeta("photoVideoConnection was unexpectedly nil")
+            return
         }
-    }
 
-    // MARK: -
+        avCaptureConnection.videoOrientation = captureOrientation
+        Logger.verbose("photoOrientation: \(captureOrientation), deviceOrientation: \(UIDevice.current.orientation)")
 
-    private func buildCaptureSettings() -> AVCapturePhotoSettings {
         let photoSettings = AVCapturePhotoSettings()
         photoSettings.flashMode = flashMode
         photoSettings.isHighResolutionPhotoEnabled = true
+        photoSettings.isAutoStillImageStabilizationEnabled = avCaptureOutput.isStillImageStabilizationSupported
 
-        photoSettings.isAutoStillImageStabilizationEnabled =
-        photoOutput.isStillImageStabilizationSupported
-
-        return photoSettings
-    }
-
-    private func availableDevices(forPosition position: AVCaptureDevice.Position) -> [AVCaptureDevice.DeviceType: AVCaptureDevice] {
-        var queryDeviceTypes: [AVCaptureDevice.DeviceType] = [ .builtInWideAngleCamera, .builtInTelephotoCamera, .builtInDualCamera ]
-        if #available(iOS 13, *) {
-            queryDeviceTypes.append(contentsOf: [ .builtInUltraWideCamera, .builtInDualWideCamera, .builtInTripleCamera ])
-        }
-        let session = AVCaptureDevice.DiscoverySession(deviceTypes: queryDeviceTypes, mediaType: .video, position: position)
-        let deviceMap = session.devices.reduce(into: [AVCaptureDevice.DeviceType: AVCaptureDevice]()) { deviceMap, device in
-            deviceMap[device.deviceType] = device
+        let photoProcessor = PhotoProcessor(delegate: delegate, captureRect: captureRect) { [weak self] in
+            self?.photoProcessors[photoSettings.uniqueID] = nil
         }
-        return deviceMap
+        photoProcessors[photoSettings.uniqueID] = photoProcessor
+
+        avCaptureOutput.capturePhoto(with: photoSettings, delegate: photoProcessor)
     }
 
     private class PhotoProcessor: NSObject, AVCapturePhotoCaptureDelegate {
-        weak var delegate: CaptureOutputDelegate?
-        let captureRect: CGRect
-        let completion: () -> Void
+        private weak var delegate: PhotoCaptureDelegate?
+        private let captureRect: CGRect
+        private let completion: () -> Void
 
-        init(delegate: CaptureOutputDelegate, captureRect: CGRect, completion: @escaping () -> Void) {
+        init(delegate: PhotoCaptureDelegate, captureRect: CGRect, completion: @escaping () -> Void) {
             self.delegate = delegate
             self.captureRect = captureRect
             self.completion = completion
@@ -1582,24 +1470,50 @@ class PhotoCaptureOutputAdaptee: NSObject, ImageCaptureOutput {
 
             guard let delegate = delegate else { return }
 
-            let result: Swift.Result<Data, Error>
+            let result: Result<Data, Error>
             do {
-                if let error = error {
+                if let error {
                     throw error
                 }
                 guard let rawData = photo.fileDataRepresentation()  else {
                     throw OWSAssertionError("photo data was unexpectedly empty")
                 }
 
-                let resizedData = try crop(photoData: rawData, toOutputRect: captureRect)
+                let resizedData = try crop(photoData: rawData, to: captureRect)
                 result = .success(resizedData)
             } catch {
                 result = .failure(error)
             }
 
             DispatchQueue.main.async {
-                delegate.captureOutputDidCapture(photoData: result)
+                delegate.photoCaptureDidProduce(result: result)
+            }
+        }
+
+        private func crop(photoData: Data, to outputRect: CGRect) throws -> Data {
+            guard
+                let originalImage = UIImage(data: photoData),
+                let cgImage = originalImage.cgImage
+            else {
+                throw OWSAssertionError("originalImage was unexpectedly nil")
+            }
+
+            guard outputRect.width > 0, outputRect.height > 0 else {
+                throw OWSAssertionError("invalid outputRect: \(outputRect)")
             }
+
+            let width = CGFloat(cgImage.width)
+            let height = CGFloat(cgImage.height)
+            let cropRect = CGRect(x: outputRect.origin.x * width,
+                                  y: outputRect.origin.y * height,
+                                  width: outputRect.size.width * width,
+                                  height: outputRect.size.height * height)
+            let croppedCGImage = cgImage.cropping(to: cropRect)!
+            let croppedUIImage = UIImage(cgImage: croppedCGImage, scale: 1, orientation: originalImage.imageOrientation)
+            guard let croppedData = croppedUIImage.jpegData(compressionQuality: 0.9) else {
+                throw OWSAssertionError("croppedData was unexpectedly nil")
+            }
+            return croppedData
         }
     }
 }
@@ -1785,33 +1699,6 @@ extension AVCaptureDevice.FlashMode {
     }
 }
 
-// MARK: -
-
-private func crop(photoData: Data, toOutputRect outputRect: CGRect) throws -> Data {
-    guard let originalImage = UIImage(data: photoData) else {
-        throw OWSAssertionError("originalImage was unexpectedly nil")
-    }
-
-    guard outputRect.width > 0, outputRect.height > 0 else {
-        throw OWSAssertionError("invalid outputRect: \(outputRect)")
-    }
-
-    var cgImage = originalImage.cgImage!
-    let width = CGFloat(cgImage.width)
-    let height = CGFloat(cgImage.height)
-    let cropRect = CGRect(x: outputRect.origin.x * width,
-                          y: outputRect.origin.y * height,
-                          width: outputRect.size.width * width,
-                          height: outputRect.size.height * height)
-
-    cgImage = cgImage.cropping(to: cropRect)!
-    let croppedUIImage = UIImage(cgImage: cgImage, scale: 1.0, orientation: originalImage.imageOrientation)
-    guard let croppedData = croppedUIImage.jpegData(compressionQuality: 0.9) else {
-        throw OWSAssertionError("croppedData was unexpectedly nil")
-    }
-    return croppedData
-}
-
 extension CMAcceleration {
 
     var deviceOrientation: AVCaptureVideoOrientation? {
diff --git a/Signal/src/ViewControllers/Photos/MediaControls.swift b/Signal/src/ViewControllers/Photos/MediaControls.swift
index 5c325593d63..b04f1a2e6f4 100644
--- a/Signal/src/ViewControllers/Photos/MediaControls.swift
+++ b/Signal/src/ViewControllers/Photos/MediaControls.swift
@@ -555,7 +555,7 @@ class CameraCaptureControl: UIView {
 
 protocol CameraZoomSelectionControlDelegate: AnyObject {
 
-    func cameraZoomControl(_ cameraZoomControl: CameraZoomSelectionControl, didSelect camera: PhotoCapture.CameraType)
+    func cameraZoomControl(_ cameraZoomControl: CameraZoomSelectionControl, didSelect camera: CameraCaptureSession.CameraType)
 
     func cameraZoomControl(_ cameraZoomControl: CameraZoomSelectionControl, didChangeZoomFactor zoomFactor: CGFloat)
 }
@@ -564,9 +564,9 @@ class CameraZoomSelectionControl: UIView {
 
     weak var delegate: CameraZoomSelectionControlDelegate?
 
-    private let availableCameras: [PhotoCapture.CameraType]
+    private let availableCameras: [CameraCaptureSession.CameraType]
 
-    var selectedCamera: PhotoCapture.CameraType
+    var selectedCamera: CameraCaptureSession.CameraType
     var currentZoomFactor: CGFloat {
         didSet {
             var viewFound = false
@@ -607,7 +607,7 @@ class CameraZoomSelectionControl: UIView {
         }
     }
 
-    required init(availableCameras: [(cameraType: PhotoCapture.CameraType, defaultZoomFactor: CGFloat)]) {
+    required init(availableCameras: [(cameraType: CameraCaptureSession.CameraType, defaultZoomFactor: CGFloat)]) {
         owsAssertDebug(!availableCameras.isEmpty, "availableCameras must not be empty.")
 
         self.availableCameras = availableCameras.map { $0.cameraType }
@@ -682,7 +682,7 @@ class CameraZoomSelectionControl: UIView {
 
     private class CameraSelectionCircleView: UIView {
 
-        let camera: PhotoCapture.CameraType
+        let camera: CameraCaptureSession.CameraType
         let defaultZoomFactor: CGFloat
         var currentZoomFactor: CGFloat = 1
 
@@ -700,7 +700,7 @@ class CameraZoomSelectionControl: UIView {
             return label
         }()
 
-        required init(camera: PhotoCapture.CameraType, defaultZoomFactor: CGFloat) {
+        required init(camera: CameraCaptureSession.CameraType, defaultZoomFactor: CGFloat) {
             self.camera = camera
             self.defaultZoomFactor = defaultZoomFactor
             self.currentZoomFactor = defaultZoomFactor
@@ -893,7 +893,7 @@ private class LockView: UIView {
     }
 }
 
-class RecordingTimerView: PillView {
+class RecordingDurationView: PillView {
 
     override init(frame: CGRect) {
         super.init(frame: frame)
@@ -911,7 +911,7 @@ class RecordingTimerView: PillView {
         addSubview(stackView)
         stackView.autoPinEdgesToSuperviewMargins()
 
-        updateView()
+        updateDurationLabel()
     }
 
     @available(*, unavailable, message: "Use init(frame:) instead")
@@ -919,6 +919,24 @@ class RecordingTimerView: PillView {
         fatalError("init(coder:) has not been implemented")
     }
 
+    var duration: TimeInterval = 0 {
+        didSet {
+            updateDurationLabel()
+        }
+    }
+
+    // If `true` red dot next to duration label will flash.
+    var isRecordingInProgress: Bool = false {
+        didSet {
+            guard oldValue != isRecordingInProgress else { return }
+            if isRecordingInProgress {
+                startAnimatingRedDot()
+            } else {
+                stopAnimatingRedDot()
+            }
+        }
+    }
+
     // MARK: - Subviews
 
     private let label: UILabel = {
@@ -939,53 +957,31 @@ class RecordingTimerView: PillView {
 
     // MARK: -
 
-    var recordingStartTime: TimeInterval?
-
-    func startCounting() {
-        guard timer == nil else { return }
-        recordingStartTime = CACurrentMediaTime()
-        timer = Timer.weakScheduledTimer(withTimeInterval: 0.1, target: self, selector: #selector(updateView), userInfo: nil, repeats: true)
-        UIView.animate(withDuration: 0.5,
-                       delay: 0,
-                       options: [.autoreverse, .repeat],
-                       animations: { self.icon.alpha = 1 })
-        updateView()
+    private func startAnimatingRedDot() {
+        UIView.animate(
+            withDuration: 0.5,
+            delay: 0,
+            options: [ .autoreverse, .repeat ],
+            animations: { self.icon.alpha = 1 }
+        )
     }
 
-    func stopCounting() {
-        timer?.invalidate()
-        timer = nil
+    private func stopAnimatingRedDot() {
         icon.layer.removeAllAnimations()
         UIView.animate(withDuration: 0.4) {
             self.icon.alpha = 0
         }
     }
 
-    // MARK: -
-
-    private var timer: Timer?
-
     private lazy var timeFormatter: DateFormatter = {
         let formatter = DateFormatter()
         formatter.dateFormat = "mm:ss"
         formatter.timeZone = TimeZone(identifier: "UTC")!
-
         return formatter
     }()
 
-    // This method should only be called when the call state is "connected".
-    var recordingDuration: TimeInterval {
-        guard let recordingStartTime = recordingStartTime else {
-            return 0
-        }
-
-        return CACurrentMediaTime() - recordingStartTime
-    }
-
-    @objc
-    private func updateView() {
-        let recordingDuration = self.recordingDuration
-        let durationDate = Date(timeIntervalSinceReferenceDate: recordingDuration)
+    private func updateDurationLabel() {
+        let durationDate = Date(timeIntervalSinceReferenceDate: duration)
         label.text = timeFormatter.string(from: durationDate)
     }
 }
@@ -1320,7 +1316,7 @@ class CameraTopBar: MediaTopBar {
     let flashModeButton = FlashModeButton()
     let batchModeButton = CaptureModeButton()
 
-    let recordingTimerView = RecordingTimerView(frame: .zero)
+    let recordingTimerView = RecordingDurationView(frame: .zero)
 
     override init(frame: CGRect) {
         cameraControlsContainerView = UIStackView(arrangedSubviews: [ batchModeButton, flashModeButton ])
@@ -1381,12 +1377,12 @@ class CameraTopBar: MediaTopBar {
         case .cameraControls:
             closeButton.setIsHidden(false, animated: animated)
             cameraControlsContainerView.setIsHidden(false, animated: animated)
-            recordingTimerView.setIsHidden(true, animated: animated)
+            recordingTimerView.setIsHidden(true, animated: false)
 
         case .closeButton:
             closeButton.setIsHidden(false, animated: animated)
             cameraControlsContainerView.setIsHidden(true, animated: animated)
-            recordingTimerView.setIsHidden(true, animated: animated)
+            recordingTimerView.setIsHidden(true, animated: false)
 
         case .videoRecording:
             closeButton.setIsHidden(true, animated: animated)
diff --git a/Signal/src/ViewControllers/Photos/PhotoCaptureViewController.swift b/Signal/src/ViewControllers/Photos/PhotoCaptureViewController.swift
index 391f059f74f..735750db40a 100644
--- a/Signal/src/ViewControllers/Photos/PhotoCaptureViewController.swift
+++ b/Signal/src/ViewControllers/Photos/PhotoCaptureViewController.swift
@@ -38,34 +38,34 @@ class PhotoCaptureViewController: OWSViewController, OWSNavigationChildControlle
     weak var dataSource: PhotoCaptureViewControllerDataSource?
     private var interactiveDismiss: PhotoCaptureInteractiveDismiss?
 
-    public lazy var photoCapture = PhotoCapture()
-    private var isCaptureReady = false {
+    public lazy var cameraCaptureSession = CameraCaptureSession(delegate: self)
+    private var isCameraReady = false {
         didSet {
-            guard isCaptureReady != oldValue else { return }
+            guard isCameraReady != oldValue else { return }
 
-            if isCaptureReady {
+            if isCameraReady {
                 BenchEventComplete(eventId: "Show-Camera")
-                VolumeButtons.shared?.addObserver(observer: photoCapture)
+                VolumeButtons.shared?.addObserver(observer: cameraCaptureSession)
                 UIApplication.shared.isIdleTimerDisabled = true
             } else {
-                VolumeButtons.shared?.removeObserver(photoCapture)
+                VolumeButtons.shared?.removeObserver(cameraCaptureSession)
                 UIApplication.shared.isIdleTimerDisabled = false
             }
         }
     }
-    private var hasCaptureStarted = false {
+    private var hasCameraStarted = false {
         didSet {
-            isCaptureReady = isViewVisible && hasCaptureStarted
+            isCameraReady = isViewVisible && hasCameraStarted
         }
     }
     private var isViewVisible = false {
         didSet {
-            isCaptureReady = isViewVisible && hasCaptureStarted
+            isCameraReady = isViewVisible && hasCameraStarted
         }
     }
 
     deinit {
-        photoCapture.stopCapture().done {
+        cameraCaptureSession.stop().done {
             Logger.debug("stopCapture completed")
         }
     }
@@ -111,7 +111,7 @@ class PhotoCaptureViewController: OWSViewController, OWSNavigationChildControlle
             previewOrientation = .portrait
         }
         UIViewController.attemptRotationToDeviceOrientation()
-        photoCapture.updateVideoPreviewConnection(toOrientation: previewOrientation)
+        cameraCaptureSession.updateVideoPreviewConnection(toOrientation: previewOrientation)
         updateIconOrientations(isAnimated: false, captureOrientation: previewOrientation)
 
         resumePhotoCapture()
@@ -225,7 +225,7 @@ class PhotoCaptureViewController: OWSViewController, OWSNavigationChildControlle
 
         // Show / hide camera controls and viewfinder.
         let hideCameraUI = composerMode != .camera
-        let isFrontCamera = photoCapture.desiredPosition == .front
+        let isFrontCamera = cameraCaptureSession.desiredPosition == .front
         frontCameraZoomControl?.setIsHidden(hideCameraUI || !isFrontCamera, animated: animated)
         rearCameraZoomControl?.setIsHidden(hideCameraUI || isFrontCamera, animated: animated)
         previewView.setIsHidden(hideCameraUI, animated: animated)
@@ -255,8 +255,9 @@ class PhotoCaptureViewController: OWSViewController, OWSNavigationChildControlle
         _internalIsRecordingVideo = isRecordingVideo
 
         updateTopBarAppearance(animated: animated)
+        topBar.recordingTimerView.isRecordingInProgress = isRecordingVideo
         if isRecordingVideo {
-            topBar.recordingTimerView.startCounting()
+            topBar.recordingTimerView.duration = 0
 
             let captureControlState: CameraCaptureControl.State = UIAccessibility.isVoiceOverRunning ? .recordingUsingVoiceOver : .recording
             let animationDuration: TimeInterval = animated ? 0.4 : 0
@@ -265,8 +266,6 @@ class PhotoCaptureViewController: OWSViewController, OWSNavigationChildControlle
                 sideBar.cameraCaptureControl.setState(captureControlState, animationDuration: animationDuration)
             }
         } else {
-            topBar.recordingTimerView.stopCounting()
-
             let animationDuration: TimeInterval = animated ? 0.2 : 0
             bottomBar.captureControl.setState(.initial, animationDuration: animationDuration)
             if let sideBar = sideBar {
@@ -359,7 +358,7 @@ class PhotoCaptureViewController: OWSViewController, OWSNavigationChildControlle
     private var lastUserFocusTapPoint: CGPoint?
 
     private var previewView: CapturePreviewView {
-        photoCapture.previewView
+        cameraCaptureSession.previewView
     }
 
     // MARK: - Text Editor
@@ -480,7 +479,7 @@ class PhotoCaptureViewController: OWSViewController, OWSNavigationChildControlle
         // Camera Zoom Controls
         cameraZoomControlIPhoneConstraints = []
 
-        let availableFrontCameras = photoCapture.cameraZoomFactorMap(forPosition: .front)
+        let availableFrontCameras = cameraCaptureSession.cameraZoomFactorMap(forPosition: .front)
         if availableFrontCameras.count > 0 {
             let cameras = availableFrontCameras.sorted { $0.0 < $1.0 }.map { ($0.0, $0.1) }
 
@@ -496,7 +495,7 @@ class PhotoCaptureViewController: OWSViewController, OWSNavigationChildControlle
             cameraZoomControlIPhoneConstraints?.append(contentsOf: cameraZoomControlConstraints)
         }
 
-        let availableRearCameras = photoCapture.cameraZoomFactorMap(forPosition: .back)
+        let availableRearCameras = cameraCaptureSession.cameraZoomFactorMap(forPosition: .back)
         if availableRearCameras.count > 0 {
             let cameras = availableRearCameras.sorted { $0.0 < $1.0 }.map { ($0.0, $0.1) }
 
@@ -544,7 +543,7 @@ class PhotoCaptureViewController: OWSViewController, OWSNavigationChildControlle
         guard sideBar == nil else { return }
 
         let sideBar = CameraSideBar(frame: .zero)
-        sideBar.cameraCaptureControl.delegate = photoCapture
+        sideBar.cameraCaptureControl.delegate = cameraCaptureSession
         sideBar.batchModeButton.addTarget(self, action: #selector(didTapBatchMode), for: .touchUpInside)
         sideBar.flashModeButton.addTarget(self, action: #selector(didTapFlashMode), for: .touchUpInside)
         sideBar.switchCameraButton.addTarget(self, action: #selector(didTapSwitchCamera), for: .touchUpInside)
@@ -647,7 +646,7 @@ class PhotoCaptureViewController: OWSViewController, OWSNavigationChildControlle
     }
 
     private func updateUIOnCameraPositionChange(animated: Bool = false) {
-        let isFrontCamera = photoCapture.desiredPosition == .front
+        let isFrontCamera = cameraCaptureSession.desiredPosition == .front
         frontCameraZoomControl?.setIsHidden(!isFrontCamera, animated: animated)
         rearCameraZoomControl?.setIsHidden(isFrontCamera, animated: animated)
         bottomBar.switchCameraButton.isFrontCameraActive = isFrontCamera
@@ -677,7 +676,7 @@ class PhotoCaptureViewController: OWSViewController, OWSNavigationChildControlle
         }
 
         // Don't "unrotate" the switch camera icon if the front facing camera had been selected.
-        let tranformFromCameraType: CGAffineTransform = photoCapture.desiredPosition == .front ? CGAffineTransform(rotationAngle: -.pi) : .identity
+        let tranformFromCameraType: CGAffineTransform = cameraCaptureSession.desiredPosition == .front ? CGAffineTransform(rotationAngle: -.pi) : .identity
 
         var buttonsToUpdate: [UIView] = [ topBar.batchModeButton, topBar.flashModeButton, bottomBar.photoLibraryButton ]
         if let cameraZoomControl = frontCameraZoomControl {
@@ -1010,7 +1009,7 @@ extension PhotoCaptureViewController {
         if let switchCameraButton = isIPadUIInRegularMode ? sideBar?.switchCameraButton : bottomBar.switchCameraButton {
             switchCameraButton.performSwitchAnimation()
         }
-        photoCapture.switchCameraPosition().done { [weak self] in
+        cameraCaptureSession.switchCameraPosition().done { [weak self] in
             self?.updateUIOnCameraPositionChange(animated: true)
         }.catch { error in
             self.showFailureUI(error: error)
@@ -1020,7 +1019,7 @@ extension PhotoCaptureViewController {
     @objc
     private func didTapFlashMode() {
         firstly {
-            photoCapture.switchFlashMode()
+            cameraCaptureSession.toggleFlashMode()
         }.done {
             self.updateFlashModeControl(animated: true)
         }.catch { error in
@@ -1092,12 +1091,12 @@ extension PhotoCaptureViewController {
     private func didPinchZoom(pinchGesture: UIPinchGestureRecognizer) {
         switch pinchGesture.state {
         case .began:
-            photoCapture.beginPinchZoom()
+            cameraCaptureSession.beginPinchZoom()
             fallthrough
         case .changed:
-            photoCapture.updatePinchZoom(withScale: pinchGesture.scale)
+            cameraCaptureSession.updatePinchZoom(withScale: pinchGesture.scale)
         case .ended:
-            photoCapture.completePinchZoom(withScale: pinchGesture.scale)
+            cameraCaptureSession.completePinchZoom(withScale: pinchGesture.scale)
         default:
             break
         }
@@ -1119,7 +1118,7 @@ extension PhotoCaptureViewController {
     private func didTapFocusExpose(tapGesture: UITapGestureRecognizer) {
         let viewLocation = tapGesture.location(in: previewView)
         let devicePoint = previewView.previewLayer.captureDevicePointConverted(fromLayerPoint: viewLocation)
-        photoCapture.focus(with: .autoFocus, exposureMode: .autoExpose, at: devicePoint, monitorSubjectAreaChange: true)
+        cameraCaptureSession.focus(with: .autoFocus, exposureMode: .autoExpose, at: devicePoint, monitorSubjectAreaChange: true)
         lastUserFocusTapPoint = devicePoint
 
         if let focusFrameSuperview = tapToFocusView.superview {
@@ -1166,20 +1165,19 @@ extension PhotoCaptureViewController {
 extension PhotoCaptureViewController {
 
     private func setupPhotoCapture() {
-        photoCapture.delegate = self
-        bottomBar.captureControl.delegate = photoCapture
+        bottomBar.captureControl.delegate = cameraCaptureSession
         if let sideBar = sideBar {
-            sideBar.cameraCaptureControl.delegate = photoCapture
+            sideBar.cameraCaptureControl.delegate = cameraCaptureSession
         }
 
         // If the session is already running, we're good to go.
-        guard !photoCapture.session.isRunning else {
-            self.hasCaptureStarted = true
+        guard !cameraCaptureSession.avCaptureSession.isRunning else {
+            self.hasCameraStarted = true
             return
         }
 
         firstly {
-            photoCapture.prepareVideoCapture()
+            cameraCaptureSession.prepare()
         }.catch { [weak self] error in
             guard let self = self else { return }
             self.showFailureUI(error: error)
@@ -1187,22 +1185,22 @@ extension PhotoCaptureViewController {
     }
 
     private func pausePhotoCapture() {
-        guard photoCapture.session.isRunning else { return }
+        guard cameraCaptureSession.avCaptureSession.isRunning else { return }
         firstly {
-            photoCapture.stopCapture()
+            cameraCaptureSession.stop()
         }.done { [weak self] in
-            self?.hasCaptureStarted = false
+            self?.hasCameraStarted = false
         }.catch { [weak self] error in
             self?.showFailureUI(error: error)
         }
     }
 
     private func resumePhotoCapture() {
-        guard !photoCapture.session.isRunning else { return }
+        guard !cameraCaptureSession.avCaptureSession.isRunning else { return }
         firstly {
-            photoCapture.resumeCapture()
+            cameraCaptureSession.resume()
         }.done { [weak self] in
-            self?.hasCaptureStarted = true
+            self?.hasCameraStarted = true
         }.catch { [weak self] error in
             self?.showFailureUI(error: error)
         }
@@ -1218,9 +1216,9 @@ extension PhotoCaptureViewController {
     }
 
     private func updateFlashModeControl(animated: Bool) {
-        topBar.flashModeButton.setFlashMode(photoCapture.flashMode, animated: animated)
+        topBar.flashModeButton.setFlashMode(cameraCaptureSession.flashMode, animated: animated)
         if let sideBar = sideBar {
-            sideBar.flashModeButton.setFlashMode(photoCapture.flashMode, animated: animated)
+            sideBar.flashModeButton.setFlashMode(cameraCaptureSession.flashMode, animated: animated)
         }
     }
 }
@@ -1242,21 +1240,21 @@ extension PhotoCaptureViewController: InteractiveDismissDelegate {
 
 extension PhotoCaptureViewController: CameraZoomSelectionControlDelegate {
 
-    func cameraZoomControl(_ cameraZoomControl: CameraZoomSelectionControl, didSelect camera: PhotoCapture.CameraType) {
+    func cameraZoomControl(_ cameraZoomControl: CameraZoomSelectionControl, didSelect camera: CameraCaptureSession.CameraType) {
         let position: AVCaptureDevice.Position = cameraZoomControl == frontCameraZoomControl ? .front : .back
-        photoCapture.switchCamera(to: camera, at: position, animated: true)
+        cameraCaptureSession.switchCamera(to: camera, at: position, animated: true)
     }
 
     func cameraZoomControl(_ cameraZoomControl: CameraZoomSelectionControl, didChangeZoomFactor zoomFactor: CGFloat) {
-        photoCapture.changeVisibleZoomFactor(to: zoomFactor, animated: true)
+        cameraCaptureSession.changeVisibleZoomFactor(to: zoomFactor, animated: true)
     }
 }
 
-extension PhotoCaptureViewController: PhotoCaptureDelegate {
+extension PhotoCaptureViewController: CameraCaptureSessionDelegate {
 
     // MARK: - Photo
 
-    func photoCaptureDidStart(_ photoCapture: PhotoCapture) {
+    func cameraCaptureSessionDidStart(_ session: CameraCaptureSession) {
         let captureFeedbackView = UIView()
         captureFeedbackView.backgroundColor = .black
         view.insertSubview(captureFeedbackView, aboveSubview: previewView)
@@ -1273,7 +1271,7 @@ extension PhotoCaptureViewController: PhotoCaptureDelegate {
         }
     }
 
-    func photoCapture(_ photoCapture: PhotoCapture, didFinishProcessing attachment: SignalAttachment) {
+    func cameraCaptureSession(_ session: CameraCaptureSession, didFinishProcessing attachment: SignalAttachment) {
         dataSource?.addMedia(attachment: attachment)
 
         updateDoneButtonAppearance()
@@ -1285,7 +1283,7 @@ extension PhotoCaptureViewController: PhotoCaptureDelegate {
         }
     }
 
-    func photoCapture(_ photoCapture: PhotoCapture, didFailProcessing error: Error) {
+    func cameraCaptureSession(_ session: CameraCaptureSession, didFailWith error: Error) {
         setIsRecordingVideo(false, animated: true)
 
         if case PhotoCaptureError.invalidVideo = error {
@@ -1296,33 +1294,32 @@ extension PhotoCaptureViewController: PhotoCaptureDelegate {
         showFailureUI(error: error)
     }
 
-    func photoCaptureCanCaptureMoreItems(_ photoCapture: PhotoCapture) -> Bool {
+    func cameraCaptureSessionCanCaptureMoreItems(_ session: CameraCaptureSession) -> Bool {
         return delegate?.photoCaptureViewControllerCanCaptureMoreItems(self) ?? false
     }
 
-    func photoCaptureDidTryToCaptureTooMany(_ photoCapture: PhotoCapture) {
+    func photoCaptureDidTryToCaptureTooMany(_ session: CameraCaptureSession) {
         delegate?.photoCaptureViewControllerDidTryToCaptureTooMany(self)
     }
 
     // MARK: - Video
 
-    func photoCaptureWillBeginRecording(_ photoCapture: PhotoCapture) {
+    func cameraCaptureSessionWillStartVideoRecording(_ session: CameraCaptureSession) {
         Logger.verbose("")
         setIsRecordingVideo(true, animated: true)
     }
 
-    func photoCaptureDidBeginRecording(_ photoCapture: PhotoCapture) {
+    func cameraCaptureSessionDidStartVideoRecording(_ session: CameraCaptureSession) {
         Logger.verbose("")
     }
 
-    func photoCaptureDidFinishRecording(_ photoCapture: PhotoCapture) {
+    func cameraCaptureSessionDidStopVideoRecording(_ session: CameraCaptureSession) {
         Logger.verbose("")
         setIsRecordingVideo(false, animated: true)
     }
 
-    func photoCaptureDidCancelRecording(_ photoCapture: PhotoCapture) {
-        Logger.verbose("")
-        setIsRecordingVideo(false, animated: true)
+    func cameraCaptureSession(_ session: CameraCaptureSession, videoRecordingDurationChanged duration: TimeInterval) {
+        topBar.recordingTimerView.duration = duration
     }
 
     // MARK: -
@@ -1334,7 +1331,7 @@ extension PhotoCaptureViewController: PhotoCaptureDelegate {
         return previewView.bounds.height / 2
     }
 
-    func photoCapture(_ photoCapture: PhotoCapture, didChangeVideoZoomFactor zoomFactor: CGFloat, forCameraPosition position: AVCaptureDevice.Position) {
+    func cameraCaptureSession(_ session: CameraCaptureSession, didChangeZoomFactor zoomFactor: CGFloat, forCameraPosition position: AVCaptureDevice.Position) {
         guard let cameraZoomControl = position == .front ? frontCameraZoomControl : rearCameraZoomControl else { return }
         cameraZoomControl.currentZoomFactor = zoomFactor
     }
@@ -1353,14 +1350,14 @@ extension PhotoCaptureViewController: PhotoCaptureDelegate {
         }
     }
 
-    func photoCapture(_ photoCapture: PhotoCapture, didChangeOrientation orientation: AVCaptureVideoOrientation) {
+    func cameraCaptureSession(_ session: CameraCaptureSession, didChangeOrientation orientation: AVCaptureVideoOrientation) {
         updateIconOrientations(isAnimated: true, captureOrientation: orientation)
         if UIDevice.current.isIPad {
-            photoCapture.updateVideoPreviewConnection(toOrientation: orientation)
+            session.updateVideoPreviewConnection(toOrientation: orientation)
         }
     }
 
-    func photoCapture(_ photoCapture: PhotoCapture, didCompleteFocusing focusPoint: CGPoint) {
+    func cameraCaptureSession(_ session: CameraCaptureSession, didFinishFocusingAt focusPoint: CGPoint) {
         completeFocusAnimation(forFocusPoint: focusPoint)
     }
 }
diff --git a/Signal/src/ViewControllers/Photos/SendMediaNavigationController.swift b/Signal/src/ViewControllers/Photos/SendMediaNavigationController.swift
index cc0eca50249..d99484420bb 100644
--- a/Signal/src/ViewControllers/Photos/SendMediaNavigationController.swift
+++ b/Signal/src/ViewControllers/Photos/SendMediaNavigationController.swift
@@ -364,15 +364,15 @@ extension SendMediaNavigationController: ImagePickerGridControllerDelegate {
     func showApprovalAfterProcessingAnyMediaLibrarySelections() {
         let backgroundBlock: (ModalActivityIndicatorViewController) -> Void = { modal in
             let approvalItemsPromise: Promise<[AttachmentApprovalItem]> = Promise.when(fulfilled: self.attachmentDraftCollection.attachmentApprovalItemPromises)
-            firstly { () -> Promise<Swift.Result<[AttachmentApprovalItem], Error>> in
+            firstly { () -> Promise<Result<[AttachmentApprovalItem], Error>> in
                 return Promise.race(
-                    approvalItemsPromise.map { attachmentApprovalItems -> Swift.Result<[AttachmentApprovalItem], Error> in
-                        Swift.Result.success(attachmentApprovalItems)
+                    approvalItemsPromise.map { attachmentApprovalItems -> Result<[AttachmentApprovalItem], Error> in
+                        .success(attachmentApprovalItems)
                     },
-                    modal.wasCancelledPromise.map { _ -> Swift.Result<[AttachmentApprovalItem], Error> in
-                        Swift.Result.failure(OWSGenericError("Modal was cancelled."))
+                    modal.wasCancelledPromise.map { _ -> Result<[AttachmentApprovalItem], Error> in
+                        .failure(OWSGenericError("Modal was cancelled."))
                     })
-            }.map { (result: Swift.Result<[AttachmentApprovalItem], Error>) in
+            }.map { (result: Result<[AttachmentApprovalItem], Error>) in
                 modal.dismiss {
                     switch result {
                     case .success(let attachmentApprovalItems):
