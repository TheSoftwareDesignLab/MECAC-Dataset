diff --git a/Signal.xcodeproj/project.pbxproj b/Signal.xcodeproj/project.pbxproj
index 25e19d3429a..01bcf9ec50f 100644
--- a/Signal.xcodeproj/project.pbxproj
+++ b/Signal.xcodeproj/project.pbxproj
@@ -773,6 +773,7 @@
 		5042EAA3287F96FB00C9B19F /* VisibleBadgeResolverTest.swift in Sources */ = {isa = PBXBuildFile; fileRef = 5042EAA2287F96FB00C9B19F /* VisibleBadgeResolverTest.swift */; };
 		50CF28F02829C94800752AB3 /* CVComponentGiftBadge.swift in Sources */ = {isa = PBXBuildFile; fileRef = 50CF28EF2829C94800752AB3 /* CVComponentGiftBadge.swift */; };
 		641CECC436F5F3EE2AC07EE9 /* Pods_SignalShareExtension.framework in Frameworks */ = {isa = PBXBuildFile; fileRef = 6657FDE7B91C2845BB3BEAB5 /* Pods_SignalShareExtension.framework */; };
+		668CAB3E289983520085A2C3 /* AudioMessagePlaybackRateView.swift in Sources */ = {isa = PBXBuildFile; fileRef = 668CAB3D289983520085A2C3 /* AudioMessagePlaybackRateView.swift */; };
 		760D93AB27A0E28600F351AC /* CoreServices.framework in Frameworks */ = {isa = PBXBuildFile; fileRef = 760D93AA27A0E28600F351AC /* CoreServices.framework */; };
 		7628DDBE2807505D009AA53D /* ImageEditorCropView.swift in Sources */ = {isa = PBXBuildFile; fileRef = 7628DDBC28075056009AA53D /* ImageEditorCropView.swift */; };
 		7628DDBF2807505D009AA53D /* RotationControl.swift in Sources */ = {isa = PBXBuildFile; fileRef = 7628DDBD2807505D009AA53D /* RotationControl.swift */; };
@@ -2998,6 +2999,7 @@
 		55D83291ED67EE1A7FC96E60 /* Pods-SignalNSE.testable release.xcconfig */ = {isa = PBXFileReference; includeInIndex = 1; lastKnownFileType = text.xcconfig; name = "Pods-SignalNSE.testable release.xcconfig"; path = "Pods/Target Support Files/Pods-SignalNSE/Pods-SignalNSE.testable release.xcconfig"; sourceTree = "<group>"; };
 		63BAA38DC365EE44110A6BD1 /* Pods-SignalTests.debug.xcconfig */ = {isa = PBXFileReference; includeInIndex = 1; lastKnownFileType = text.xcconfig; name = "Pods-SignalTests.debug.xcconfig"; path = "Pods/Target Support Files/Pods-SignalTests/Pods-SignalTests.debug.xcconfig"; sourceTree = "<group>"; };
 		6657FDE7B91C2845BB3BEAB5 /* Pods_SignalShareExtension.framework */ = {isa = PBXFileReference; explicitFileType = wrapper.framework; includeInIndex = 0; path = Pods_SignalShareExtension.framework; sourceTree = BUILT_PRODUCTS_DIR; };
+		668CAB3D289983520085A2C3 /* AudioMessagePlaybackRateView.swift */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.swift; path = AudioMessagePlaybackRateView.swift; sourceTree = "<group>"; };
 		70377AAA1918450100CAF501 /* MobileCoreServices.framework */ = {isa = PBXFileReference; lastKnownFileType = wrapper.framework; name = MobileCoreServices.framework; path = System/Library/Frameworks/MobileCoreServices.framework; sourceTree = SDKROOT; };
 		748A5CAEDD7C919FC64C6807 /* Pods_SignalTests.framework */ = {isa = PBXFileReference; explicitFileType = wrapper.framework; includeInIndex = 0; path = Pods_SignalTests.framework; sourceTree = BUILT_PRODUCTS_DIR; };
 		760D93AA27A0E28600F351AC /* CoreServices.framework */ = {isa = PBXFileReference; lastKnownFileType = wrapper.framework; name = CoreServices.framework; path = System/Library/Frameworks/CoreServices.framework; sourceTree = SDKROOT; };
@@ -5564,6 +5566,7 @@
 				34277A5C20751BDC006049F2 /* OWSQuotedMessageView.m */,
 				3470C8732554926200F5847C /* QuotedMessageView.swift */,
 				348EE28D25B897BF00814FC2 /* ReusableMediaView.swift */,
+				668CAB3D289983520085A2C3 /* AudioMessagePlaybackRateView.swift */,
 			);
 			path = Cells;
 			sourceTree = "<group>";
@@ -10091,6 +10094,7 @@
 				34B6A905218B4C91007C4606 /* TypingIndicatorInteraction.swift in Sources */,
 				884DB95027DE67BB00C6A309 /* StoryContextViewController.swift in Sources */,
 				34A4D87F2677B23100A794E7 /* ConversationViewController+MessageActions.swift in Sources */,
+				668CAB3E289983520085A2C3 /* AudioMessagePlaybackRateView.swift in Sources */,
 				887CD47F247307D900FDD265 /* DeviceTransferService+Restore.swift in Sources */,
 				8829883925B979F900DEE1E3 /* ThemeSettingsTableViewController.swift in Sources */,
 				888B6D4D25B2523800E2A662 /* ConversationViewController+Wallpaper.swift in Sources */,
diff --git a/Signal/Images.xcassets/x-10.imageset/Contents.json b/Signal/Images.xcassets/x-10.imageset/Contents.json
new file mode 100644
index 00000000000..cc3b839b48c
--- /dev/null
+++ b/Signal/Images.xcassets/x-10.imageset/Contents.json
@@ -0,0 +1,12 @@
+{
+  "images" : [
+    {
+      "filename" : "x-10.pdf",
+      "idiom" : "universal"
+    }
+  ],
+  "info" : {
+    "author" : "xcode",
+    "version" : 1
+  }
+}
diff --git a/Signal/Images.xcassets/x-10.imageset/x-10.pdf b/Signal/Images.xcassets/x-10.imageset/x-10.pdf
new file mode 100644
index 00000000000..47e4460148f
Binary files /dev/null and b/Signal/Images.xcassets/x-10.imageset/x-10.pdf differ
diff --git a/Signal/src/ViewControllers/ConversationView/CV/CVComponents/CVComponentAudioAttachment.swift b/Signal/src/ViewControllers/ConversationView/CV/CVComponents/CVComponentAudioAttachment.swift
index 756194bee0d..f9ebb45a7a9 100644
--- a/Signal/src/ViewControllers/ConversationView/CV/CVComponents/CVComponentAudioAttachment.swift
+++ b/Signal/src/ViewControllers/ConversationView/CV/CVComponents/CVComponentAudioAttachment.swift
@@ -64,10 +64,14 @@ public class CVComponentAudioAttachment: CVComponentBase, CVComponent {
 
         owsAssertDebug(attachment.isAudio)
         // TODO: We might want to convert AudioMessageView into a form that can be reused.
-        let audioMessageView = AudioMessageView(audioAttachment: audioAttachment,
-                                                isIncoming: isIncoming,
-                                                componentDelegate: componentDelegate,
-                                                mediaCache: mediaCache)
+        let audioMessageView = AudioMessageView(
+            threadUniqueId: itemModel.thread.uniqueId,
+            audioAttachment: audioAttachment,
+            audioPlaybackRate: itemModel.itemViewState.audioPlaybackRate,
+            isIncoming: isIncoming,
+            componentDelegate: componentDelegate,
+            mediaCache: mediaCache
+        )
         if let incomingMessage = interaction as? TSIncomingMessage {
             audioMessageView.setViewed(incomingMessage.wasViewed, animated: false)
         } else if let outgoingMessage = interaction as? TSOutgoingMessage {
@@ -75,8 +79,7 @@ public class CVComponentAudioAttachment: CVComponentBase, CVComponent {
         }
         audioMessageView.configureForRendering(
             cellMeasurement: cellMeasurement,
-            conversationStyle: conversationStyle,
-            audioPlaybackRate: itemViewState.audioPlaybackRate
+            conversationStyle: conversationStyle
         )
         componentView.audioMessageView = audioMessageView
         stackView.configure(config: stackViewConfig,
@@ -116,7 +119,6 @@ public class CVComponentAudioAttachment: CVComponentBase, CVComponent {
             audioAttachment: audioAttachment,
             isIncoming: isIncoming,
             conversationStyle: conversationStyle,
-            audioPlaybackRate: itemViewState.audioPlaybackRate,
             measurementBuilder: measurementBuilder
         ).ceil
         let audioInfo = audioSize.asManualSubviewInfo
@@ -132,11 +134,24 @@ public class CVComponentAudioAttachment: CVComponentBase, CVComponent {
 
     // MARK: - Events
 
-    public override func handleTap(sender: UITapGestureRecognizer,
-                                   componentDelegate: CVComponentDelegate,
-                                   componentView: CVComponentView,
-                                   renderItem: CVRenderItem) -> Bool {
+    public override func handleTap(
+        sender: UITapGestureRecognizer,
+        componentDelegate: CVComponentDelegate,
+        componentView: CVComponentView,
+        renderItem: CVRenderItem
+    ) -> Bool {
+        if
+            let audioMessageView = (componentView as? CVComponentViewAudioAttachment)?.audioMessageView,
+            audioMessageView.handleTap(sender: sender, itemModel: renderItem.itemModel)
+        {
+            return true
+        }
+
         if audioAttachment.isDownloaded {
+            cvAudioPlayer.setPlaybackRate(
+                renderItem.itemViewState.audioPlaybackRate,
+                forThreadUniqueId: renderItem.itemModel.thread.uniqueId
+            )
             cvAudioPlayer.togglePlayState(forAudioAttachment: audioAttachment)
             return true
 
diff --git a/Signal/src/ViewControllers/ConversationView/Cells/AudioMessagePlaybackRateView.swift b/Signal/src/ViewControllers/ConversationView/Cells/AudioMessagePlaybackRateView.swift
new file mode 100644
index 00000000000..6ce0eb7ff57
--- /dev/null
+++ b/Signal/src/ViewControllers/ConversationView/Cells/AudioMessagePlaybackRateView.swift
@@ -0,0 +1,441 @@
+//
+//  Copyright (c) 2022 Open Whisper Systems. All rights reserved.
+//
+
+import Foundation
+import UIKit
+
+// MARK: - AudioPlaybackRate
+
+enum AudioPlaybackRate: Float {
+    case slow = 0.5
+    case normal = 1
+    case fast = 1.5
+    case extraFast = 2
+}
+
+// MARK: - AudioMessagePlaybackRateView
+
+class AudioMessagePlaybackRateView: ManualLayoutViewWithLayer {
+
+    private let threadUniqueId: String
+    private let audioAttachment: AudioAttachment
+    private let isIncoming: Bool
+
+    private var playbackRate: AudioPlaybackRate
+
+    private let label = CVLabel()
+    private let imageView = CVImageView()
+
+    init(
+        threadUniqueId: String,
+        audioAttachment: AudioAttachment,
+        playbackRate: AudioPlaybackRate,
+        isIncoming: Bool
+    ) {
+        self.threadUniqueId = threadUniqueId
+        self.audioAttachment = audioAttachment
+        self.isIncoming = isIncoming
+        self.playbackRate = playbackRate
+        super.init(name: "AudioMessagePlaybackRateView")
+
+        // layoutBlocks get called once per frame change.
+        // no need to set one up per subview added, just
+        // have a single block that triggers an update to
+        // the frames of all the subviews.
+        addSubview(imageView)
+        addSubview(label, withLayoutBlock: { [weak self] _ in
+            self?.setSubviewFrames()
+        })
+
+        // start invisible
+        self.alpha = 0
+        self.backgroundColor = _backgroundColor
+        self.layer.cornerRadius = Constants.cornerRadius
+
+        Self.playbackRateLabelConfig(
+            playbackRate: playbackRate,
+            color: textColor
+        ).applyForRendering(label: label)
+        self.imageView.image = Constants.image?.asTintedImage(color: textColor)
+    }
+
+    @available(swift, obsoleted: 1.0)
+    required init(name: String) {
+        owsFail("Do not use this initializer.")
+    }
+
+    // MARK: - Animating Changes
+
+    private var isVisible: Bool = false {
+        didSet {
+            self.alpha = isVisible ? 1 : 0
+        }
+    }
+    private var isAnimatingVisibility: Bool?
+
+    public func setVisibility(
+        _ visible: Bool,
+        animated: Bool = true,
+        completion: (() -> Void)? = nil
+    ) {
+        // NOTE: can't use `isHidden` state because ManualStackView gets
+        // unhappy if one of its subviews hides. Use alpha instead.
+        guard isVisible != visible, isAnimatingVisibility != visible else {
+            completion?()
+            return
+        }
+
+        let fromScale = CATransform3DScale(
+            CATransform3DIdentity,
+            visible ? 0 : 1,
+            visible ? 0 : 1,
+            1
+        )
+        let toScale = CATransform3DScale(
+            CATransform3DIdentity,
+            visible ? 1 : 0,
+            visible ? 1 : 0,
+            1
+        )
+        layer.transform = toScale
+
+        let wrappedCompletion = {
+            self.isAnimatingVisibility = nil
+            self.isVisible = visible
+            completion?()
+        }
+
+        guard animated else {
+            wrappedCompletion()
+            return
+        }
+
+        // Make it visible so we can see the animation.
+        isVisible = true
+        isAnimatingVisibility = visible
+
+        CATransaction.begin()
+        layer.removeAnimation(forKey: Constants.animationName)
+
+        let animation = Self.createSpringAnimation()
+        animation.fillMode = .forwards
+        animation.fromValue = fromScale
+        animation.toValue = toScale
+
+        CATransaction.setCompletionBlock(wrappedCompletion)
+        layer.add(animation, forKey: Constants.animationName)
+        CATransaction.commit()
+    }
+
+    public func setPlaybackRate(
+        _ playbackRate: AudioPlaybackRate,
+        animated: Bool = true,
+        completion: (() -> Void)? = nil
+    ) {
+        guard self.playbackRate != playbackRate else {
+            completion?()
+            return
+        }
+        self.playbackRate = playbackRate
+
+        let setContent = { [weak self] in
+            guard let strongSelf = self else {
+                return
+            }
+            strongSelf.setSubviewFrames()
+            Self.playbackRateLabelConfig(
+                playbackRate: strongSelf.playbackRate,
+                color: strongSelf.textColor
+            ).applyForRendering(label: strongSelf.label)
+        }
+
+        // Don't interrupt the appearance animation.
+        guard animated, self.isVisible, self.isAnimatingVisibility == nil else {
+            setContent()
+            completion?()
+            return
+        }
+
+        CATransaction.begin()
+        layer.removeAnimation(forKey: Constants.animationName)
+
+        let animation = Self.createSpringAnimation()
+        let fromScale = CATransform3DScale(
+            CATransform3DIdentity,
+            1,
+            1,
+            1
+        )
+        animation.fromValue = fromScale
+        let toScale = CATransform3DScale(
+            CATransform3DIdentity,
+            Constants.changeAnimationScale,
+            Constants.changeAnimationScale,
+            1
+        )
+        animation.toValue = toScale
+        animation.autoreverses = true
+
+        CATransaction.setCompletionBlock {
+            completion?()
+        }
+        layer.add(animation, forKey: Constants.animationName)
+        CATransaction.commit()
+
+        // Schedule the actual text update to happen halfway through,
+        // right at the reversal point.
+        DispatchQueue.main.asyncAfter(
+            deadline: .now() + Constants.animationDuration,
+            execute: setContent
+        )
+        return
+    }
+
+    private static func createSpringAnimation() -> CASpringAnimation {
+        let animation = CASpringAnimation(keyPath: "transform")
+        animation.damping = Constants.animationDamping
+        animation.stiffness = Constants.animationStiffness
+        animation.mass = Constants.animationMass
+        animation.duration = Constants.animationDuration
+        animation.speed = Constants.animationSpeed
+        return animation
+    }
+
+    // MARK: - Tapping
+
+    public func handleTap(
+        sender: UITapGestureRecognizer,
+        itemModel: CVItemModel,
+        componentDelegate: CVComponentDelegate?
+    ) -> Bool {
+        guard
+            let attachmentId = audioAttachment.attachmentStream?.uniqueId,
+            cvAudioPlayer.audioPlaybackState(forAttachmentId: attachmentId) == .playing
+        else {
+            return false
+        }
+        // Check that the tap is within the bounding box, but
+        // expand that to a minimum height/width if its too small.
+        let location = sender.location(in: self)
+        let tapTargetBounds = bounds.insetBy(
+            dx: -0.5 * max(0, Constants.minTapTargetSize - bounds.width),
+            dy: -0.5 * max(0, Constants.minTapTargetSize - bounds.height)
+        )
+        guard tapTargetBounds.contains(location) else {
+            return false
+        }
+        let newPlaybackRate = playbackRate.next
+        self.cvAudioPlayer.setPlaybackRate(newPlaybackRate.rawValue, forThreadUniqueId: threadUniqueId)
+
+        // Hold off updates until we animate the change.
+        let animationCompletion = componentDelegate?.cvc_beginCellAnimation(
+            maximumDuration: Constants.maxAnimationDuration
+        )
+
+        let reloadGroup = DispatchGroup()
+
+        // First write the update to the db, this persists the change and ensures the
+        // reload we do afterwards pulls the updated rate.
+        reloadGroup.enter()
+        itemModel.databaseStorage.asyncWrite(
+            block: {
+                itemModel.threadAssociatedData.updateWith(
+                    audioPlaybackRate: newPlaybackRate.rawValue,
+                    updateStorageService: true,
+                    transaction: $0
+                )
+            },
+            completion: {
+                reloadGroup.leave()
+            })
+
+        // Trigger the animation which also updates the playback rate value.
+        reloadGroup.enter()
+        setPlaybackRate(newPlaybackRate) {
+            reloadGroup.leave()
+            animationCompletion?()
+        }
+
+        reloadGroup.notify(queue: .main) { [weak componentDelegate] in
+            // Once the animation _and_ the db update complete, issue a reload.
+            // This reloads _everything_, which is way overkill, but there's no easy way
+            // to reload only ThreadAssociatedData without a heavy refactor.
+            // This only happens on direct user input, anyway, so its probably not a
+            // big deal since it therefore only happens on human timescales.
+            componentDelegate?.cvc_enqueueReloadWithoutCaches()
+        }
+
+        return true
+    }
+
+    // MARK: - Sizing
+
+    public static func measure(maxWidth: CGFloat) -> CGSize {
+        // Always size this view for the max playback rate size.
+        let labelConfig = Self.playbackRateLabelConfig(
+            playbackRate: AudioPlaybackRate.rateForLargestDisplayText,
+            color: .white // Color doesn't matter for sizing.
+        )
+        let nonLabelWidth = Constants.imageSize + Constants.margins.totalWidth
+        let labelSize = CVText.measureLabel(config: labelConfig, maxWidth: maxWidth - nonLabelWidth)
+
+        let height = Constants.margins.totalHeight + max(labelSize.height, Constants.imageSize)
+
+        return CGSize(
+            width: labelSize.width + nonLabelWidth,
+            height: height
+        )
+    }
+
+    // MARK: - Laying out subviews
+
+    private func setSubviewFrames() {
+        let labelConfig = Self.playbackRateLabelConfig(
+            playbackRate: playbackRate,
+            color: .white // Color doesn't matter for sizing.
+        )
+        let labelSize = CVText.measureLabel(
+            config: labelConfig,
+            maxWidth: bounds.width
+        )
+        let labelWidth = labelSize.width
+        let imageSize = Constants.imageSize
+
+        // We want the label and image as a whole to be centered,
+        // so pad each side with remaining width equally.
+        let contentWidth = labelWidth + imageSize
+        let sidePadding = (bounds.width - contentWidth) / 2
+
+        label.frame = CGRect(
+            x: sidePadding,
+            y: (bounds.height - labelSize.height) / 2,
+            width: labelWidth,
+            height: labelSize.height
+        )
+        imageView.frame = CGRect(
+            x: sidePadding + labelWidth,
+            y: (bounds.height - imageSize) / 2,
+            width: imageSize,
+            height: imageSize
+        )
+    }
+
+    // MARK: - Colors
+
+    private lazy var _backgroundColor = isIncoming
+        ? (Theme.isDarkThemeEnabled ? UIColor.ows_white : .ows_black).withAlphaComponent(0.08)
+        : UIColor.ows_whiteAlpha20
+
+    private lazy var textColor: UIColor = isIncoming
+        ? (Theme.isDarkThemeEnabled ? .ows_gray15 : .ows_gray60)
+        : .ows_white
+
+    // MARK: - Configs
+
+    private static func playbackRateLabelConfig(
+        playbackRate: AudioPlaybackRate,
+        color: UIColor
+    ) -> CVLabelConfig {
+        let text = playbackRate.displayText
+        // Limit the max font size to avoid overlap.
+        var font = Constants.font
+        if font.pointSize > Constants.maxFontSize {
+            font = font.withSize(Constants.maxFontSize)
+        }
+        font = font.ows_semibold
+        return CVLabelConfig(
+            text: text,
+            font: font,
+            textColor: color,
+            textAlignment: .right
+        )
+    }
+
+    fileprivate enum Constants {
+        static let cornerRadius: CGFloat = 6
+        static var font: UIFont { UIFont.ows_dynamicTypeFootnote }
+        static let maxFontSize: CGFloat = 20
+
+        static var imageSize: CGFloat {
+            switch UIApplication.shared.preferredContentSizeCategory {
+            case .extraSmall, .small, .medium, .large, .extraLarge:
+                return 10
+            default:
+                return 16
+            }
+        }
+        static var image: UIImage? {
+            switch UIApplication.shared.preferredContentSizeCategory {
+            case .extraSmall, .small, .medium, .large, .extraLarge:
+                return UIImage(named: "x-10")
+            default:
+                return UIImage(named: "x-16")
+            }
+        }
+        static let margins = UIEdgeInsets(hMargin: 8, vMargin: 2)
+
+        static let animationName = "scale"
+        static let animationDuration: TimeInterval = 0.15
+        static let animationDamping: CGFloat = 1.15
+        static let animationStiffness: CGFloat = 100
+        static let animationMass: CGFloat = 1
+        static let animationSpeed: Float = 1
+        static let changeAnimationScale: CGFloat = 1.3
+
+        static var maxAnimationDuration: TimeInterval {
+            return animationDuration * 2 // 2x for autoreverse
+        }
+
+        static let minTapTargetSize: CGFloat = 44
+    }
+}
+
+// MARK: - AudioPlaybackRate extension
+
+extension AudioPlaybackRate {
+    init(rawValue: Float) {
+        switch rawValue {
+        case _ where rawValue <= 0.5:
+            self = .slow
+        case _ where rawValue < 1.5:
+            self = .normal
+        case _ where rawValue < 2:
+            self = .fast
+        default:
+            self = .extraFast
+        }
+    }
+
+    var next: AudioPlaybackRate {
+        switch self {
+        case .slow:
+            return .normal
+        case .normal:
+            return .fast
+        case .fast:
+            return .extraFast
+        case .extraFast:
+            return .slow
+        }
+    }
+
+    var displayText: String {
+        // Instead of dealing with float formatting, just
+        // hardcode since there's only 4 cases anyway.
+        switch self {
+        case .slow:
+            return LocalizationNotNeeded(".5")
+        case .normal:
+            return LocalizationNotNeeded("1")
+        case .fast:
+            return LocalizationNotNeeded("1.5")
+        case .extraFast:
+            return LocalizationNotNeeded("2")
+        }
+    }
+
+    static var rateForLargestDisplayText: AudioPlaybackRate {
+        return .fast
+    }
+}
diff --git a/Signal/src/ViewControllers/ConversationView/Cells/AudioMessageView.swift b/Signal/src/ViewControllers/ConversationView/Cells/AudioMessageView.swift
index 357cf7d08db..7cd121f43ff 100644
--- a/Signal/src/ViewControllers/ConversationView/Cells/AudioMessageView.swift
+++ b/Signal/src/ViewControllers/ConversationView/Cells/AudioMessageView.swift
@@ -4,27 +4,29 @@
 
 import Foundation
 import Lottie
+import UIKit
 
 class AudioMessageView: ManualStackView {
 
+    // MARK: - State
+
+    private let threadUniqueId: String
     private let audioAttachment: AudioAttachment
     private var attachment: TSAttachment { audioAttachment.attachment }
     private var attachmentStream: TSAttachmentStream? { audioAttachment.attachmentStream }
     private var durationSeconds: TimeInterval { audioAttachment.durationSeconds }
 
+    // Initially set to the value from the database (via itemViewState).
+    // When the user changes the rate, model updates are paused via
+    // `cvc_beginCellAnimation` and this value is updated. Once animations
+    // are done, the whole cell gets recreated with the new plaback rate
+    // value.
+    private var audioPlaybackRate: AudioPlaybackRate
+
     private let isIncoming: Bool
     private weak var componentDelegate: CVComponentDelegate?
     private let mediaCache: CVMediaCache
 
-    private let playedDotAnimation: Lottie.AnimationView
-    private let playedDotContainer = ManualLayoutView(name: "playedDotContainer")
-    private let playPauseAnimation: Lottie.AnimationView
-    private let playPauseContainer = ManualLayoutView.circleView(name: "playPauseContainer")
-    private let playbackTimeLabel = CVLabel()
-    private let progressSlider = UISlider()
-    private let waveformProgress: AudioWaveformProgressView
-    private let waveformContainer = ManualLayoutView(name: "waveformContainer")
-
     private var audioPlaybackState: AudioPlaybackState {
         cvAudioPlayer.audioPlaybackState(forAttachmentId: attachment.uniqueId)
     }
@@ -43,27 +45,59 @@ class AudioMessageView: ManualStackView {
         updateContents(animated: animated)
     }
 
-    init(audioAttachment: AudioAttachment,
-         isIncoming: Bool,
-         componentDelegate: CVComponentDelegate,
-         mediaCache: CVMediaCache) {
+    // MARK: - Views
 
+    private let playedDotAnimation: Lottie.AnimationView
+    private let playedDotContainer = ManualLayoutView(name: "playedDotContainer")
+    private let playPauseAnimation: Lottie.AnimationView
+    private let playPauseContainer = ManualLayoutView.circleView(name: "playPauseContainer")
+    private let playbackTimeLabel = CVLabel()
+    private let playbackRateView: AudioMessagePlaybackRateView
+    private let progressSlider = UISlider()
+    private let waveformProgress: AudioWaveformProgressView
+    private let waveformContainer = ManualLayoutView(name: "waveformContainer")
+
+    // MARK: Init
+
+    init(
+        threadUniqueId: String,
+        audioAttachment: AudioAttachment,
+        audioPlaybackRate: Float,
+        isIncoming: Bool,
+        componentDelegate: CVComponentDelegate,
+        mediaCache: CVMediaCache
+    ) {
+        self.threadUniqueId = threadUniqueId
         self.audioAttachment = audioAttachment
         self.isIncoming = isIncoming
         self.componentDelegate = componentDelegate
         self.mediaCache = mediaCache
+        self.audioPlaybackRate = AudioPlaybackRate(rawValue: audioPlaybackRate)
 
         self.waveformProgress = AudioWaveformProgressView(mediaCache: mediaCache)
         self.playedDotAnimation = mediaCache.buildLottieAnimationView(name: "audio-played-dot")
         self.playPauseAnimation = mediaCache.buildLottieAnimationView(name: "playPauseButton")
 
+        self.playbackRateView = AudioMessagePlaybackRateView(
+            threadUniqueId: threadUniqueId,
+            audioAttachment: audioAttachment,
+            playbackRate: AudioPlaybackRate(rawValue: audioPlaybackRate),
+            isIncoming: isIncoming
+        )
+
         super.init(name: "AudioMessageView")
     }
 
+    @available(swift, obsoleted: 1.0)
+    required init(name: String, arrangedSubviews: [UIView] = []) {
+        owsFail("Do not use this initializer.")
+    }
+
+    // MARK: - Rendering
+
     public func configureForRendering(
         cellMeasurement: CVCellMeasurement,
-        conversationStyle: ConversationStyle,
-        audioPlaybackRate: Float
+        conversationStyle: ConversationStyle
     ) {
 
         var outerSubviews = [UIView]()
@@ -137,7 +171,7 @@ class AudioMessageView: ManualStackView {
             leftView = playPauseContainer
         } else if let attachmentPointer = audioAttachment.attachmentPointer {
             leftView = CVAttachmentProgressView(direction: .download(attachmentPointer: attachmentPointer),
-                                                style: .withoutCircle(diameter: Self.animationSize),
+                                                style: .withoutCircle(diameter: Constants.animationSize),
                                                 isDarkThemeEnabled: conversationStyle.isDarkThemeEnabled,
                                                 mediaCache: mediaCache)
         } else {
@@ -162,6 +196,7 @@ class AudioMessageView: ManualStackView {
                 .transparentSpacer(),
                 playbackTimeLabel,
                 playedDotContainer,
+                playbackRateView,
                 .transparentSpacer()
         ]
 
@@ -184,6 +219,8 @@ class AudioMessageView: ManualStackView {
         cvAudioPlayer.addListener(self)
     }
 
+    // MARK: - Measurement
+
     private static let measurementKey_topInnerStack = "CVComponentAudioAttachment.measurementKey_topInnerStack"
     private static let measurementKey_bottomInnerStack = "CVComponentAudioAttachment.measurementKey_bottomInnerStack"
     private static let measurementKey_outerStack = "CVComponentAudioAttachment.measurementKey_outerStack"
@@ -193,7 +230,6 @@ class AudioMessageView: ManualStackView {
         audioAttachment: AudioAttachment,
         isIncoming: Bool,
         conversationStyle: ConversationStyle,
-        audioPlaybackRate: Float,
         measurementBuilder: CVCellMeasurement.Builder
     ) -> CGSize {
         owsAssertDebug(maxWidth > 0)
@@ -207,12 +243,12 @@ class AudioMessageView: ManualStackView {
         }
 
         var topInnerSubviewInfos = [ManualStackSubviewInfo]()
-        let leftViewSize = CGSize(square: animationSize)
+        let leftViewSize = CGSize(square: Constants.animationSize)
         topInnerSubviewInfos.append(leftViewSize.asManualSubviewInfo(hasFixedSize: true))
 
         topInnerSubviewInfos.append(CGSize(width: 12, height: 0).asManualSubviewInfo(hasFixedWidth: true))
 
-        let waveformSize = CGSize(width: 0, height: waveformHeight)
+        let waveformSize = CGSize(width: 0, height: Constants.waveformHeight)
         topInnerSubviewInfos.append(waveformSize.asManualSubviewInfo(hasFixedHeight: true))
 
         topInnerSubviewInfos.append(CGSize(width: 6, height: 0).asManualSubviewInfo(hasFixedWidth: true))
@@ -231,20 +267,16 @@ class AudioMessageView: ManualStackView {
                                                                              conversationStyle: conversationStyle)
         let playbackTimeLabelSize = CVText.measureLabel(config: playbackTimeLabelConfig, maxWidth: maxWidth)
 
+        let playbackRateSize = AudioMessagePlaybackRateView.measure(maxWidth: maxWidth)
+
         var bottomInnerSubviewInfos: [ManualStackSubviewInfo] = [
             playbackTimeLabelSize.asManualSubviewInfo(hasFixedSize: true),
-            dotSize.asManualSubviewInfo(hasFixedSize: true)
+            dotSize.asManualSubviewInfo(hasFixedSize: true),
+            playbackRateSize.asManualSubviewInfo(hasFixedSize: true)
         ]
 
-        // The playback controls are always rendered RTL, but the timestamps remain pinned to the
-        // trailing edge of the message bubble, as such we need to re-arrange the spacing to accommodate.
-        if CurrentAppContext().isRTL {
-            bottomInnerSubviewInfos.insert(CGSize.zero.asManualSubviewInfo(hasFixedSize: true), at: 0)
-            bottomInnerSubviewInfos.append(.empty)
-        } else {
-            bottomInnerSubviewInfos.insert(CGSize(width: 44, height: 0).asManualSubviewInfo(hasFixedWidth: true), at: 0)
-            bottomInnerSubviewInfos.append(.empty)
-        }
+        bottomInnerSubviewInfos.insert(CGSize.zero.asManualSubviewInfo(hasFixedWidth: true), at: 0)
+        bottomInnerSubviewInfos.append(.empty)
 
         let bottomInnerStackMeasurement = ManualStackView.measure(config: bottomInnerStackConfig,
                                                             measurementBuilder: measurementBuilder,
@@ -261,15 +293,12 @@ class AudioMessageView: ManualStackView {
         return outerStackMeasurement.measuredSize
     }
 
-    @available(swift, obsoleted: 1.0)
-    required init(name: String, arrangedSubviews: [UIView] = []) {
-        owsFail("Do not use this initializer.")
-    }
+    // MARK: - View Configs
 
     private static var outerStackConfig: CVStackViewConfig {
         CVStackViewConfig(axis: .vertical,
                           alignment: .fill,
-                          spacing: vSpacing,
+                          spacing: Constants.vSpacing,
                           layoutMargins: .zero)
     }
 
@@ -277,13 +306,13 @@ class AudioMessageView: ManualStackView {
         CVStackViewConfig(axis: .horizontal,
                           alignment: .center,
                           spacing: 0,
-                          layoutMargins: innerLayoutMargins)
+                          layoutMargins: Constants.innerLayoutMargins)
     }
 
     private static var bottomInnerStackConfig: CVStackViewConfig {
         CVStackViewConfig(axis: .horizontal,
                           alignment: .center,
-                          spacing: 8,
+                          spacing: Constants.bottomInnerStackSpacing,
                           layoutMargins: .zero)
     }
 
@@ -304,7 +333,7 @@ class AudioMessageView: ManualStackView {
         }
 
         return CVLabelConfig(text: text,
-                             font: labelFont,
+                             font: Constants.labelFont,
                              textColor: conversationStyle.bubbleTextColor(isIncoming: isIncoming))
     }
 
@@ -329,9 +358,39 @@ class AudioMessageView: ManualStackView {
     private static func playbackTimeLabelConfig(text: String,
                                                 isIncoming: Bool,
                                                 conversationStyle: ConversationStyle) -> CVLabelConfig {
-        CVLabelConfig(text: text,
-                      font: UIFont.ows_dynamicTypeCaption1.ows_monospaced,
-                      textColor: conversationStyle.bubbleSecondaryTextColor(isIncoming: isIncoming))
+        return CVLabelConfig(
+            text: text,
+            font: UIFont.ows_dynamicTypeCaption1Clamped,
+            textColor: conversationStyle.bubbleSecondaryTextColor(isIncoming: isIncoming)
+        )
+    }
+
+    // MARK: - Constants
+
+    fileprivate enum Constants {
+        static let labelFont: UIFont = .ows_dynamicTypeCaption2
+        static let waveformHeight: CGFloat = 32
+        static let animationSize: CGFloat = 40
+        static let vSpacing: CGFloat = 2
+        static let innerLayoutMargins = UIEdgeInsets(hMargin: 0, vMargin: 4)
+
+        static var bottomInnerStackSpacing: CGFloat {
+            switch UIApplication.shared.preferredContentSizeCategory {
+            case .extraSmall, .small, .medium, .large, .extraLarge:
+                return 8
+            default:
+                return 4
+            }
+        }
+    }
+
+    // MARK: - Tapping
+
+    public func handleTap(
+        sender: UITapGestureRecognizer,
+        itemModel: CVItemModel
+    ) -> Bool {
+        return playbackRateView.handleTap(sender: sender, itemModel: itemModel, componentDelegate: componentDelegate)
     }
 
     // MARK: - Scrubbing
@@ -365,14 +424,6 @@ class AudioMessageView: ManualStackView {
 
     // MARK: - Contents
 
-    private static var labelFont: UIFont = .ows_dynamicTypeCaption2
-    private static var waveformHeight: CGFloat = 32
-    private static var animationSize: CGFloat = 40
-    private static var vSpacing: CGFloat = 2
-    private static var innerLayoutMargins: UIEdgeInsets {
-        UIEdgeInsets(hMargin: 0, vMargin: 4)
-    }
-
     private lazy var playedColor: UIColor = isIncoming
         ? (Theme.isDarkThemeEnabled ? .ows_gray15 : .ows_gray60)
         : .ows_white
@@ -391,8 +442,11 @@ class AudioMessageView: ManualStackView {
         updatePlaybackState(animated: animated)
         updateViewedState(animated: animated)
         updateAudioProgress()
+        updatePlaybackRate(animated: animated)
     }
 
+    // MARK: Progress
+
     private var audioProgressRatio: CGFloat {
         if let overrideProgress = self.overrideProgress {
             return overrideProgress.clamp01()
@@ -412,6 +466,8 @@ class AudioMessageView: ManualStackView {
         }
     }
 
+    // MARK: Playback State
+
     private func updatePlaybackState(animated: Bool = true) {
         let isPlaying = audioPlaybackState == .playing
         let destination: AnimationProgressTime = isPlaying ? 1 : 0
@@ -429,22 +485,6 @@ class AudioMessageView: ManualStackView {
         }
     }
 
-    private func updateViewedState(animated: Bool = true) {
-        let destination: AnimationProgressTime = isViewed ? 1 : 0
-
-        // Do nothing if we're already there.
-        guard destination != playedDotAnimation.currentProgress else { return }
-
-        if animated {
-            let endCellAnimation = componentDelegate?.cvc_beginCellAnimation(maximumDuration: 0.2)
-            playedDotAnimation.play(toProgress: destination) { _ in
-                endCellAnimation?()
-            }
-        } else {
-            playedDotAnimation.currentProgress = destination
-        }
-    }
-
     private func updateElapsedTime(_ elapsedSeconds: TimeInterval) {
         let timeRemaining = durationSeconds - elapsedSeconds
         playbackTimeLabel.text = OWSFormat.localizedDurationString(from: timeRemaining)
@@ -480,9 +520,39 @@ class AudioMessageView: ManualStackView {
             .asTintedImage(color: color)?
             .resizableImage(withCapInsets: UIEdgeInsets(top: 0, leading: 2, bottom: 0, trailing: 2))
     }
+
+    // MARK: Viewed State
+
+    private func updateViewedState(animated: Bool = true) {
+        let destination: AnimationProgressTime = isViewed ? 1 : 0
+
+        // Do nothing if we're already there.
+        guard destination != playedDotAnimation.currentProgress else { return }
+
+        if animated {
+            let endCellAnimation = componentDelegate?.cvc_beginCellAnimation(maximumDuration: 0.2)
+            playedDotAnimation.play(toProgress: destination) { _ in
+                endCellAnimation?()
+            }
+        } else {
+            playedDotAnimation.currentProgress = destination
+        }
+    }
+
+    // MARK: Playback Rate
+
+    private func updatePlaybackRate(animated: Bool) {
+        let isPlaying: Bool = {
+            guard let attachmentStream = attachmentStream else {
+                return false
+            }
+            return cvAudioPlayer.audioPlaybackState(forAttachmentId: attachmentStream.uniqueId) == .playing
+        }()
+        playbackRateView.setVisibility(isPlaying, animated: animated)
+    }
 }
 
-// MARK: -
+// MARK: - CVAudioPlayerListener
 
 extension AudioMessageView: CVAudioPlayerListener {
     func audioPlayerStateDidChange(attachmentId: String) {
